{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXkculjkEzwq",
        "outputId": "ac5ddc0e-c432-4db1-e63e-9af983e43ac5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# 1. Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import pickle\n",
        "import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gc\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "M0_l1x8WMbEV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Navigate to your project\n",
        "os.listdir('/content/drive/MyDrive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvTmXcgmE3PX",
        "outputId": "55f02078-1efb-4e88-eeff-2a610223477c"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Colab Notebooks',\n",
              " 'h-and-m-personalized-fashion-recommendations',\n",
              " 'human+activity+recognition+using+smartphones',\n",
              " 'Memory machines',\n",
              " 'LLM_Project.gdoc',\n",
              " 'Dataset']"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "project_path = '/content/drive/MyDrive/Dataset/'\n",
        "raw_data_path = f'{project_path}raw_data/'"
      ],
      "metadata": {
        "id": "S-Q1GsHDE3P3"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Extract one quarter"
      ],
      "metadata": {
        "id": "B4UvySTCQzdD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Extracting one quarter\n",
        "# First, let's see what zip files you have\n",
        "print(\"Files in Dataset folder:\")\n",
        "print(os.listdir(project_path))\n",
        "\n",
        "# Extract Q1 2024 first (to explore and build pipeline)\n",
        "zip_file_path = f'{project_path}faers_ascii_2024q1.zip'\n",
        "\n",
        "# Create a folder to extract Q1 data\n",
        "extract_path = '/content/2024_Q1/'\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "# Extract the zip file\n",
        "print(f\"\\nExtracting {zip_file_path}...\")\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "    print(\"Extraction complete!\")\n",
        "\n",
        "# See what files were extracted\n",
        "print(f\"\\nExtracted files in {extract_path}:\")\n",
        "for root, dirs, files in os.walk(extract_path):\n",
        "    for file in files:\n",
        "        file_path = os.path.join(root, file)\n",
        "        file_size = os.path.getsize(file_path) / (1024*1024)  # Size in MB\n",
        "        print(f\"  {file}: {file_size:.2f} MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VoMkKCF3E3R6",
        "outputId": "5ea3b6e9-5afe-4a69-c8e9-7b2e1e2c5003"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files in Dataset folder:\n",
            "['faers_ascii_2024Q4.zip', 'faers_ascii_2024q2.zip', 'faers_ascii_2024q3.zip', 'faers_ascii_2024q1.zip', 'processed_quarters', 'faers_ascii_2025q2.zip', 'faers_ascii_2025q1.zip', 'faers_ascii_2025q3.zip']\n",
            "\n",
            "Extracting /content/drive/MyDrive/Dataset/faers_ascii_2024q1.zip...\n",
            "Extraction complete!\n",
            "\n",
            "Extracted files in /content/2024_Q1/:\n",
            "  Readme.pdf: 0.13 MB\n",
            "  FAQs.pdf: 0.22 MB\n",
            "  RPSR24Q1.pdf: 0.14 MB\n",
            "  INDI24Q1.txt: 55.38 MB\n",
            "  INDI24Q1.pdf: 0.13 MB\n",
            "  OUTC24Q1.pdf: 0.13 MB\n",
            "  OUTC24Q1.txt: 6.20 MB\n",
            "  DEMO24Q1.pdf: 0.21 MB\n",
            "  THER24Q1.pdf: 0.13 MB\n",
            "  THER24Q1.txt: 20.61 MB\n",
            "  REAC24Q1.pdf: 0.13 MB\n",
            "  DRUG24Q1.pdf: 0.30 MB\n",
            "  DEMO24Q1.txt: 57.38 MB\n",
            "  REAC24Q1.txt: 53.39 MB\n",
            "  RPSR24Q1.txt: 0.26 MB\n",
            "  DRUG24Q1.txt: 186.83 MB\n",
            "  ASC_NTS.pdf: 0.33 MB\n",
            "  DELETE24Q1.txt: 0.04 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Locating extracted ASCII files"
      ],
      "metadata": {
        "id": "ekdotk7uQ2k1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if there's a 2024_Q1 folder (from our extraction)\n",
        "if '2024_Q1' in os.listdir('/content/'):\n",
        "    print(\"Contents of /content/2024_Q1/:\")\n",
        "    print(os.listdir('/content/2024_Q1/'))\n",
        "\n",
        "    # Check for subdirectories\n",
        "    for item in os.listdir('/content/2024_Q1/'):\n",
        "        item_path = f'/content/2024_Q1/{item}'\n",
        "        if os.path.isdir(item_path):\n",
        "            print(f\"\\nContents of {item_path}:\")\n",
        "            files = os.listdir(item_path)\n",
        "            # Show first 10 files\n",
        "            for f in files[:10]:\n",
        "                print(f\"  - {f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fVx6H86PT_j",
        "outputId": "76fa7d56-48d2-44fc-bfc3-d859211d87d6"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents of /content/2024_Q1/:\n",
            "['Readme.pdf', 'ASCII', 'FAQs.pdf', 'Deleted']\n",
            "\n",
            "Contents of /content/2024_Q1/ASCII:\n",
            "  - RPSR24Q1.pdf\n",
            "  - INDI24Q1.txt\n",
            "  - INDI24Q1.pdf\n",
            "  - OUTC24Q1.pdf\n",
            "  - OUTC24Q1.txt\n",
            "  - DEMO24Q1.pdf\n",
            "  - THER24Q1.pdf\n",
            "  - THER24Q1.txt\n",
            "  - REAC24Q1.pdf\n",
            "  - DRUG24Q1.pdf\n",
            "\n",
            "Contents of /content/2024_Q1/Deleted:\n",
            "  - DELETE24Q1.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Exploe file sttructure"
      ],
      "metadata": {
        "id": "3ROKBwG9SSYh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the correct path to your ASCII files\n",
        "ascii_folder = '/content/2024_Q1/ASCII/'"
      ],
      "metadata": {
        "id": "fd9Ev45NQf1s"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get list of only .txt files (excluding PDFs)\n",
        "txt_files = [f for f in os.listdir(ascii_folder) if f.endswith('.txt')]\n",
        "print(f\"Found {len(txt_files)} text files:\")\n",
        "for f in sorted(txt_files):\n",
        "    size_mb = os.path.getsize(os.path.join(ascii_folder, f)) / (1024*1024)\n",
        "    print(f\"  {f}: {size_mb:.2f} MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KU6sxDp_SWQf",
        "outputId": "71bb2d38-e49a-4fcf-b759-068c40b94adb"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 7 text files:\n",
            "  DEMO24Q1.txt: 57.38 MB\n",
            "  DRUG24Q1.txt: 186.83 MB\n",
            "  INDI24Q1.txt: 55.38 MB\n",
            "  OUTC24Q1.txt: 6.20 MB\n",
            "  REAC24Q1.txt: 53.39 MB\n",
            "  RPSR24Q1.txt: 0.26 MB\n",
            "  THER24Q1.txt: 20.61 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the core files for your project\n",
        "Ascii_files = {\n",
        "    'DEMO': 'DEMO24Q1.txt',\n",
        "    'DRUG': 'DRUG24Q1.txt',\n",
        "    'REAC': 'REAC24Q1.txt',\n",
        "    'OUTC': 'OUTC24Q1.txt',\n",
        "    'INDI': 'INDI24Q1.txt',\n",
        "    'THER': 'THER24Q1.txt',\n",
        "    'RSPR': 'RPSR24Q1.txt'\n",
        "}\n",
        "\n",
        "# Check each file's structure\n",
        "for file_type, filename in Ascii_files.items():\n",
        "    if filename in txt_files:\n",
        "        file_path = os.path.join(ascii_folder, filename)\n",
        "\n",
        "        # Read first 3 rows to see structure\n",
        "        df_sample = pd.read_csv(file_path, sep='$', nrows=3, encoding='latin-1', low_memory=False)\n",
        "\n",
        "        print(f\"\\n{file_type} File: {filename}\")\n",
        "        print(f\"Columns ({len(df_sample.columns)}): {list(df_sample.columns)}\")\n",
        "        print(\"\\nFirst 2 rows:\")\n",
        "        print(df_sample.head(2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P735xSURSaoz",
        "outputId": "61a4c4ee-7a9d-4893-b299-4fcfddab67a6"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DEMO File: DEMO24Q1.txt\n",
            "Columns (25): ['primaryid', 'caseid', 'caseversion', 'i_f_code', 'event_dt', 'mfr_dt', 'init_fda_dt', 'fda_dt', 'rept_cod', 'auth_num', 'mfr_num', 'mfr_sndr', 'lit_ref', 'age', 'age_cod', 'age_grp', 'sex', 'e_sub', 'wt', 'wt_cod', 'rept_dt', 'to_mfr', 'occp_cod', 'reporter_country', 'occr_country']\n",
            "\n",
            "First 2 rows:\n",
            "    primaryid    caseid  caseversion i_f_code    event_dt    mfr_dt  \\\n",
            "0  1001678125  10016781           25        F  20120330.0  20240125   \n",
            "1  1002872124  10028721           24        F  20171025.0  20240228   \n",
            "\n",
            "   init_fda_dt    fda_dt rept_cod  auth_num  ... age_grp sex e_sub  wt wt_cod  \\\n",
            "0     20140318  20240129      EXP       NaN  ...     NaN   F     Y NaN    NaN   \n",
            "1     20140321  20240304      EXP       NaN  ...     NaN   F     Y NaN    NaN   \n",
            "\n",
            "    rept_dt to_mfr occp_cod  reporter_country  occr_country  \n",
            "0  20240129    NaN       HP                CA            CA  \n",
            "1  20240304    NaN       MD                CA            CA  \n",
            "\n",
            "[2 rows x 25 columns]\n",
            "\n",
            "DRUG File: DRUG24Q1.txt\n",
            "Columns (20): ['primaryid', 'caseid', 'drug_seq', 'role_cod', 'drugname', 'prod_ai', 'val_vbm', 'route', 'dose_vbm', 'cum_dose_chr', 'cum_dose_unit', 'dechal', 'rechal', 'lot_num', 'exp_dt', 'nda_num', 'dose_amt', 'dose_unit', 'dose_form', 'dose_freq']\n",
            "\n",
            "First 2 rows:\n",
            "    primaryid    caseid  drug_seq role_cod     drugname             prod_ai  \\\n",
            "0  1001678125  10016781         1       PS  SANDOSTATIN  OCTREOTIDE ACETATE   \n",
            "1  1001678125  10016781         2       SS  SANDOSTATIN  OCTREOTIDE ACETATE   \n",
            "\n",
            "   val_vbm          route                                dose_vbm  \\\n",
            "0        1   Subcutaneous  UNK, TID (cont 02 weeks post 01st LAR)   \n",
            "1        1  Intramuscular                              20 mg, QMO   \n",
            "\n",
            "   cum_dose_chr  cum_dose_unit dechal rechal  lot_num  exp_dt  nda_num  \\\n",
            "0           NaN            NaN      Y      U      NaN     NaN    19667   \n",
            "1           NaN            NaN      Y      U      NaN     NaN    19667   \n",
            "\n",
            "   dose_amt dose_unit  dose_form dose_freq  \n",
            "0       NaN       NaN        NaN       TID  \n",
            "1      20.0        MG        NaN    /MONTH  \n",
            "\n",
            "REAC File: REAC24Q1.txt\n",
            "Columns (4): ['primaryid', 'caseid', 'pt', 'drug_rec_act']\n",
            "\n",
            "First 2 rows:\n",
            "    primaryid    caseid             pt  drug_rec_act\n",
            "0  1001678125  10016781   Eye pruritus           NaN\n",
            "1  1001678125  10016781  Sensitisation           NaN\n",
            "\n",
            "OUTC File: OUTC24Q1.txt\n",
            "Columns (3): ['primaryid', 'caseid', 'outc_cod']\n",
            "\n",
            "First 2 rows:\n",
            "    primaryid    caseid outc_cod\n",
            "0  1001678125  10016781       OT\n",
            "1  1002872124  10028721       OT\n",
            "\n",
            "INDI File: INDI24Q1.txt\n",
            "Columns (4): ['primaryid', 'caseid', 'indi_drug_seq', 'indi_pt']\n",
            "\n",
            "First 2 rows:\n",
            "    primaryid    caseid  indi_drug_seq                indi_pt\n",
            "0  1001678125  10016781              1  Neuroendocrine tumour\n",
            "1  1001678125  10016781              4  Neuroendocrine tumour\n",
            "\n",
            "THER File: THER24Q1.txt\n",
            "Columns (7): ['primaryid', 'caseid', 'dsg_drug_seq', 'start_dt', 'end_dt', 'dur', 'dur_cod']\n",
            "\n",
            "First 2 rows:\n",
            "    primaryid    caseid  dsg_drug_seq  start_dt    end_dt  dur  dur_cod\n",
            "0  1001678125  10016781             1    201201  201204.0  NaN      NaN\n",
            "1  1001678125  10016781             2  20120327       NaN  NaN      NaN\n",
            "\n",
            "RSPR File: RPSR24Q1.txt\n",
            "Columns (3): ['primaryid', 'caseid', 'rpsr_cod']\n",
            "\n",
            "First 2 rows:\n",
            "   primaryid    caseid rpsr_cod\n",
            "0  233577761  23357776      CSM\n",
            "1  233578071  23357807      CSM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Initial Data Inspection & Quality Check"
      ],
      "metadata": {
        "id": "VicEGI7zadRJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the dataset\n",
        "# 1. Load DEMO (Demographics)\n",
        "print(\"1. Loading DEMO...\")\n",
        "demo = pd.read_csv(f'{ascii_folder}DEMO24Q1.txt', sep='$', encoding='latin-1', low_memory=False)\n",
        "print(f\"   ✓ DEMO loaded: {demo.shape[0]:,} records, {demo.shape[1]} columns\")\n",
        "\n",
        "# 2. Load DRUG (Drug Information)\n",
        "print(\"\\n2. Loading DRUG...\")\n",
        "drug = pd.read_csv(f'{ascii_folder}DRUG24Q1.txt', sep='$', encoding='latin-1', low_memory=False)\n",
        "print(f\"   ✓ DRUG loaded: {drug.shape[0]:,} records\")\n",
        "\n",
        "# 3. Load REAC (Reactions/Adverse Events)\n",
        "print(\"\\n3. Loading REAC...\")\n",
        "reac = pd.read_csv(f'{ascii_folder}REAC24Q1.txt', sep='$', encoding='latin-1', low_memory=False)\n",
        "print(f\"   ✓ REAC loaded: {reac.shape[0]:,} records\")\n",
        "\n",
        "# 4. Load OUTC (Outcomes)\n",
        "print(\"\\n4. Loading OUTC...\")\n",
        "outc = pd.read_csv(f'{ascii_folder}OUTC24Q1.txt', sep='$', encoding='latin-1', low_memory=False)\n",
        "print(f\"   ✓ OUTC loaded: {outc.shape[0]:,} records\")\n",
        "\n",
        "# 5. Load INDI (Indications)\n",
        "print(\"\\n5. Loading INDI...\")\n",
        "indi = pd.read_csv(f'{ascii_folder}INDI24Q1.txt', sep='$', encoding='latin-1', low_memory=False)\n",
        "print(f\"   ✓ INDI loaded: {indi.shape[0]:,} records\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyAXcLyXTKxD",
        "outputId": "a5d2906d-0f74-4485-8d5d-606f4ed2274d"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Loading DEMO...\n",
            "   ✓ DEMO loaded: 406,184 records, 25 columns\n",
            "\n",
            "2. Loading DRUG...\n",
            "   ✓ DRUG loaded: 1,909,327 records\n",
            "\n",
            "3. Loading REAC...\n",
            "   ✓ REAC loaded: 1,445,416 records\n",
            "\n",
            "4. Loading OUTC...\n",
            "   ✓ OUTC loaded: 295,044 records\n",
            "\n",
            "5. Loading INDI...\n",
            "   ✓ INDI loaded: 1,186,115 records\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing primaryid (critical for joining)\n",
        "print(\"Missing Primary IDs:\")\n",
        "print(f\"  DEMO: {demo['primaryid'].isna().sum()}\")\n",
        "print(f\"  DRUG: {drug['primaryid'].isna().sum()}\")\n",
        "print(f\"  REAC: {reac['primaryid'].isna().sum()}\")\n",
        "print(f\"  OUTC: {outc['primaryid'].isna().sum()}\")\n",
        "print(f\"  INDI: {indi['primaryid'].isna().sum()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJeRpo3kan9u",
        "outputId": "a22edd4a-1dd3-4baf-8007-9bd6bde402cf"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing Primary IDs:\n",
            "  DEMO: 0\n",
            "  DRUG: 0\n",
            "  REAC: 0\n",
            "  OUTC: 0\n",
            "  INDI: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for duplicates\n",
        "print(\"\\nDuplicate Records Check:\")\n",
        "print(f\"  DEMO duplicate primaryids: {demo['primaryid'].duplicated().sum()}\")\n",
        "print(f\"  DRUG duplicate (primaryid, drug_seq): {drug[['primaryid', 'drug_seq']].duplicated().sum()}\")\n",
        "print(f\"  REAC duplicate (primaryid, pt): {reac[['primaryid', 'pt']].duplicated().sum()}\")\n",
        "#OUTC: Multiple outcomes per patient is NORMAL\n",
        "#INDI: Multiple indications per patient is NORMAL"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8pRWFPIbHTz",
        "outputId": "e13bede6-e040-42e2-de0f-ecd9ce38cec9"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Duplicate Records Check:\n",
            "  DEMO duplicate primaryids: 0\n",
            "  DRUG duplicate (primaryid, drug_seq): 92\n",
            "  REAC duplicate (primaryid, pt): 21934\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Handle DRUG duplicates\n",
        "print(\"1. Cleaning DRUG duplicates...\")\n",
        "print(f\"   Before: {drug.shape[0]:,} records\")\n",
        "\n",
        "# Check what kind of duplicates these are\n",
        "dup_drugs = drug[drug[['primaryid', 'drug_seq']].duplicated(keep=False)]\n",
        "print(f\"   Sample duplicate drug entries:\")\n",
        "sample_dup = dup_drugs.head(10)[['primaryid', 'drug_seq', 'drugname', 'role_cod']]\n",
        "print(sample_dup)\n",
        "\n",
        "# Remove exact duplicates (keeping first occurrence)\n",
        "drug_clean = drug.drop_duplicates(subset=['primaryid', 'drug_seq'], keep='first')\n",
        "print(f\"   After: {drug_clean.shape[0]:,} records\")\n",
        "print(f\"   Removed: {drug.shape[0] - drug_clean.shape[0]} duplicate drug records\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sq6fyZ5Yb1PP",
        "outputId": "2f93da47-e8ac-4c25-f134-897418def857"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Cleaning DRUG duplicates...\n",
            "   Before: 1,909,327 records\n",
            "   Sample duplicate drug entries:\n",
            "        primaryid  drug_seq    drugname role_cod\n",
            "809486  233626421         1  TACROLIMUS       PS\n",
            "809487  233626421         1  TACROLIMUS       PS\n",
            "809506  233626461         1       TALTZ       PS\n",
            "809507  233626461         1       TALTZ       PS\n",
            "809511  233626481         1       TALTZ       PS\n",
            "809512  233626481         1       TALTZ       PS\n",
            "809513  233626491         1       TALTZ       PS\n",
            "809514  233626491         1       TALTZ       PS\n",
            "810176  233628921         1     MENOPUR       PS\n",
            "810177  233628921         1     MENOPUR       PS\n",
            "   After: 1,909,235 records\n",
            "   Removed: 92 duplicate drug records\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Handle REAC duplicates\n",
        "print(\"\\n2. Cleaning REAC duplicates...\")\n",
        "print(f\"   Before: {reac.shape[0]:,} records\")\n",
        "\n",
        "# Check what kind of duplicates these are\n",
        "dup_reacs = reac[reac[['primaryid', 'pt']].duplicated(keep=False)]\n",
        "print(f\"   Sample duplicate reaction entries:\")\n",
        "sample_dup_reac = dup_reacs.head(10)[['primaryid', 'pt']]\n",
        "print(sample_dup_reac)\n",
        "\n",
        "# For reactions, duplicates might mean the same reaction reported multiple times\n",
        "# We should keep only unique primaryid-reaction pairs\n",
        "reac_clean = reac.drop_duplicates(subset=['primaryid', 'pt'], keep='first')\n",
        "print(f\"   After: {reac_clean.shape[0]:,} records\")\n",
        "print(f\"   Removed: {reac.shape[0] - reac_clean.shape[0]} duplicate reaction records\")\n",
        "\n",
        "# 3. Verify no duplicates remain\n",
        "print(\"\\n3. Verifying cleanup...\")\n",
        "print(f\"   DRUG duplicates remaining: {drug_clean[['primaryid', 'drug_seq']].duplicated().sum()}\")\n",
        "print(f\"   REAC duplicates remaining: {reac_clean[['primaryid', 'pt']].duplicated().sum()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-L4UQN0cSAu",
        "outputId": "4f05d34b-33e5-4cfc-ee07-d7140e9f2bef"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "2. Cleaning REAC duplicates...\n",
            "   Before: 1,445,416 records\n",
            "   Sample duplicate reaction entries:\n",
            "      primaryid                              pt\n",
            "11   1001678125             Injection site pain\n",
            "14   1001678125             Injection site pain\n",
            "206  1014222252                     Head injury\n",
            "211  1014222252              Hypoaesthesia oral\n",
            "213  1014222252                     Head injury\n",
            "216  1014222252              Hypoaesthesia oral\n",
            "234  1014222252           Loss of consciousness\n",
            "235  1014222252           Loss of consciousness\n",
            "292  1016133060  Intraocular pressure increased\n",
            "311  1016133060  Intraocular pressure increased\n",
            "   After: 1,423,482 records\n",
            "   Removed: 21934 duplicate reaction records\n",
            "\n",
            "3. Verifying cleanup...\n",
            "   DRUG duplicates remaining: 0\n",
            "   REAC duplicates remaining: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Update the dataframes for further processing\n",
        "drug = drug_clean.copy()\n",
        "reac = reac_clean.copy()"
      ],
      "metadata": {
        "id": "ZHK2aNOsce4J"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find common primaryids across files\n",
        "print(\"\\nOverlap Analysis:\")\n",
        "demo_ids = set(demo['primaryid'].unique())\n",
        "drug_ids = set(drug['primaryid'].unique())\n",
        "reac_ids = set(reac['primaryid'].unique())\n",
        "outc_ids = set(outc['primaryid'].unique())\n",
        "indi_ids = set(indi['primaryid'].unique())\n",
        "\n",
        "common_ids = demo_ids.intersection(drug_ids).intersection(reac_ids)\n",
        "\n",
        "print(f\"  Total unique reports in DEMO: {len(demo_ids):,}\")\n",
        "print(f\"  Reports with drugs: {len(drug_ids):,}\")\n",
        "print(f\"  Reports with reactions: {len(reac_ids):,}\")\n",
        "print(f\"  Reports with outcomes: {len(outc_ids):,}\")\n",
        "print(f\"  Reports with indications: {len(indi_ids):,}\")\n",
        "print(f\"  Common reports (DEMO ∩ DRUG ∩ REAC): {len(common_ids):,}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZwD-6Ckckho",
        "outputId": "b55240d3-a253-4ee9-ba5b-c106590aa8b6"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Overlap Analysis:\n",
            "  Total unique reports in DEMO: 406,184\n",
            "  Reports with drugs: 406,184\n",
            "  Reports with reactions: 406,184\n",
            "  Reports with outcomes: 222,364\n",
            "  Reports with indications: 380,226\n",
            "  Common reports (DEMO ∩ DRUG ∩ REAC): 406,184\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check drug role distribution\n",
        "print(\"\\nDrug Role Distribution:\")\n",
        "print(drug['role_cod'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noy0AD9rctKM",
        "outputId": "114aaabd-4e64-401b-f757-3ac98810a45e"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Drug Role Distribution:\n",
            "role_cod\n",
            "SS    819688\n",
            "C     672902\n",
            "PS    406184\n",
            "I      10461\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Data Preprocessing"
      ],
      "metadata": {
        "id": "K4q6a2TcesR8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Understanding role codes:\n",
        "role_meanings = {\n",
        "    'PS': 'Primary Suspect - Drug suspected to cause the adverse event',\n",
        "    'SS': 'Secondary Suspect - Other drugs also suspected',\n",
        "    'C': 'Concomitant - Drug taken but not suspected',\n",
        "    'I': 'Interacting - Drug that may interact with suspect drugs'\n",
        "}\n",
        "\n",
        "print(\"Drug Role Definitions:\")\n",
        "for code, meaning in role_meanings.items():\n",
        "    count = drug['role_cod'].value_counts().get(code, 0)\n",
        "    pct = (count / len(drug)) * 100\n",
        "    print(f\"  {code}: {count:,} ({pct:.1f}%) - {meaning}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvxTmpLBc7rJ",
        "outputId": "fefca22d-73a6-4479-c74f-69835a686aae"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drug Role Definitions:\n",
            "  PS: 406,184 (21.3%) - Primary Suspect - Drug suspected to cause the adverse event\n",
            "  SS: 819,688 (42.9%) - Secondary Suspect - Other drugs also suspected\n",
            "  C: 672,902 (35.2%) - Concomitant - Drug taken but not suspected\n",
            "  I: 10,461 (0.5%) - Interacting - Drug that may interact with suspect drugs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Suspect drugs only (PS + SS + I) - Most important for adverse event associations\n",
        "suspect_drugs = drug[drug['role_cod'].isin(['PS', 'SS', 'I'])].copy()\n",
        "print(f\"\\n1. SUSPECT DRUGS (PS+SS+I): {suspect_drugs.shape[0]:,} records\")\n",
        "print(f\"   These are drugs suspected to cause adverse events\")\n",
        "\n",
        "# 2. Primary suspects only - Highest confidence drug-event associations\n",
        "primary_drugs = drug[drug['role_cod'] == 'PS'].copy()\n",
        "print(f\"\\n2. PRIMARY SUSPECTS ONLY: {primary_drugs.shape[0]:,} records\")\n",
        "print(f\"   These have the strongest association with adverse events\")\n",
        "\n",
        "# 3. All drugs including concomitant - For drug interaction analysis\n",
        "all_drugs = drug.copy()\n",
        "print(f\"\\n3. ALL DRUGS (including concomitant): {all_drugs.shape[0]:,} records\")\n",
        "print(f\"   Use this for drug-drug interaction discovery\")\n",
        "\n",
        "# Check how many patients have each type of drug\n",
        "print(\"\\n\" + \"-\"*40)\n",
        "print(\"Patients by drug type:\")\n",
        "print(f\"  Patients with Primary Suspect drugs: {primary_drugs['primaryid'].nunique():,}\")\n",
        "print(f\"  Patients with Secondary Suspect drugs: {drug[drug['role_cod']=='SS']['primaryid'].nunique():,}\")\n",
        "print(f\"  Patients with Concomitant drugs: {drug[drug['role_cod']=='C']['primaryid'].nunique():,}\")\n",
        "print(f\"  Patients with Interacting drugs: {drug[drug['role_cod']=='I']['primaryid'].nunique():,}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEIbUr5vfpjF",
        "outputId": "21f5f3bd-5f11-4399-84c7-c1e67fffba0e"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "1. SUSPECT DRUGS (PS+SS+I): 1,236,333 records\n",
            "   These are drugs suspected to cause adverse events\n",
            "\n",
            "2. PRIMARY SUSPECTS ONLY: 406,184 records\n",
            "   These have the strongest association with adverse events\n",
            "\n",
            "3. ALL DRUGS (including concomitant): 1,909,235 records\n",
            "   Use this for drug-drug interaction discovery\n",
            "\n",
            "----------------------------------------\n",
            "Patients by drug type:\n",
            "  Patients with Primary Suspect drugs: 406,184\n",
            "  Patients with Secondary Suspect drugs: 172,663\n",
            "  Patients with Concomitant drugs: 109,972\n",
            "  Patients with Interacting drugs: 2,327\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyze polypharmacy by role\n",
        "print(\"Drug combinations analysis:\")\n",
        "drug_counts = drug.groupby(['primaryid', 'role_cod']).size().unstack(fill_value=0)\n",
        "print(f\"  Avg Primary Suspects per patient: {drug_counts['PS'].mean():.2f}\")\n",
        "print(f\"  Avg Secondary Suspects per patient: {drug_counts['SS'].mean():.2f}\")\n",
        "print(f\"  Avg Concomitant drugs per patient: {drug_counts['C'].mean():.2f}\")\n",
        "\n",
        "# Patients with multiple suspects (potential drug interactions)\n",
        "multi_suspect = drug_counts[(drug_counts['PS'] > 0) & (drug_counts['SS'] > 0)]\n",
        "print(f\"  Patients with both PS and SS drugs: {len(multi_suspect):,} (potential interactions)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MK-GwBXgIAb",
        "outputId": "ccc5f2f1-d864-4121-c03c-e955676bd538"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drug combinations analysis:\n",
            "  Avg Primary Suspects per patient: 1.00\n",
            "  Avg Secondary Suspects per patient: 2.02\n",
            "  Avg Concomitant drugs per patient: 1.66\n",
            "  Patients with both PS and SS drugs: 172,663 (potential interactions)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DRUG DATASET"
      ],
      "metadata": {
        "id": "QpQkLhYpiuOa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 1: Create focused drug datasets\n",
        "\n",
        "# A. Main dataset - Suspect drugs only\n",
        "suspect_drugs = drug[drug['role_cod'].isin(['PS', 'SS', 'I'])].copy()\n",
        "suspect_drugs['drugname_clean'] = suspect_drugs['drugname'].str.upper().str.strip()\n",
        "\n",
        "# Remove invalid drug names\n",
        "invalid_names = ['UNKNOWN', 'UNK', 'NULL', 'NA', 'N/A', 'NOT SPECIFIED', 'UNSPECIFIED', 'BLINDED']\n",
        "suspect_drugs = suspect_drugs[~suspect_drugs['drugname_clean'].isin(invalid_names)]\n",
        "print(f\"✓ Suspect drugs cleaned: {suspect_drugs.shape[0]:,} records\")\n",
        "\n",
        "# B. Concomitant drugs - Keep separately for interaction discovery\n",
        "concomitant_drugs = drug[drug['role_cod'] == 'C'].copy()\n",
        "concomitant_drugs['drugname_clean'] = concomitant_drugs['drugname'].str.upper().str.strip()\n",
        "concomitant_drugs = concomitant_drugs[~concomitant_drugs['drugname_clean'].isin(invalid_names)]\n",
        "print(f\"✓ Concomitant drugs cleaned: {concomitant_drugs.shape[0]:,} records\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZarJK8shPKf",
        "outputId": "5bb53405-0fc6-494d-8e1c-8780c32e784a"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Suspect drugs cleaned: 1,236,333 records\n",
            "✓ Concomitant drugs cleaned: 672,902 records\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Create patient-level drug profiles\n",
        "print(\"Step 2: Creating patient drug profiles...\")\n",
        "\n",
        "# Get suspect drug combinations per patient\n",
        "patient_suspect_drugs = suspect_drugs.groupby('primaryid').agg({\n",
        "    'drugname_clean': lambda x: list(set(x)),\n",
        "    'role_cod': lambda x: dict(x.value_counts())\n",
        "}).rename(columns={'drugname_clean': 'suspect_drugs', 'role_cod': 'role_distribution'})\n",
        "\n",
        "patient_suspect_drugs['num_suspect_drugs'] = patient_suspect_drugs['suspect_drugs'].apply(len)\n",
        "\n",
        "# Get concomitant drugs per patient\n",
        "patient_concom_drugs = concomitant_drugs.groupby('primaryid')['drugname_clean'].apply(lambda x: list(set(x))).to_frame()\n",
        "patient_concom_drugs.columns = ['concomitant_drugs']\n",
        "patient_concom_drugs['num_concom_drugs'] = patient_concom_drugs['concomitant_drugs'].apply(len)\n",
        "\n",
        "print(f\"Drug profiles created for {len(patient_suspect_drugs):,} patients\")\n",
        "\n",
        "patient_suspect_drugs['is_interaction_case'] = (patient_suspect_drugs['num_suspect_drugs'] > 1).astype(int)     ##Flag for cases with multiple suspect drugs\n",
        "\n",
        "primary_drug = suspect_drugs[suspect_drugs['role_cod'] == 'PS'].groupby('primaryid')['drugname_clean'].first() ##The main PS drug (every case has exactly one)\n",
        "patient_suspect_drugs['primary_drug'] = patient_suspect_drugs.index.map(primary_drug)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLb-FPV-ijon",
        "outputId": "a372457d-f993-495e-f75b-d938e1d73a07"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 2: Creating patient drug profiles...\n",
            "Drug profiles created for 406,184 patients\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Identify key patterns\n",
        "print(\"\\nStep 3: Analyzing drug patterns...\")\n",
        "\n",
        "# Polypharmacy categories\n",
        "patient_suspect_drugs['polypharmacy_category'] = pd.cut(\n",
        "    patient_suspect_drugs['num_suspect_drugs'],\n",
        "    bins=[0, 1, 2, 5, 10, 100],\n",
        "    labels=['monotherapy', 'dual_therapy', 'moderate_poly', 'severe_poly', 'extreme_poly']\n",
        ")\n",
        "\n",
        "print(\"Polypharmacy distribution (suspect drugs):\")\n",
        "print(patient_suspect_drugs['polypharmacy_category'].value_counts())\n",
        "\n",
        "# Top drug combinations (for PS+SS patients)\n",
        "multi_drug_patients = patient_suspect_drugs[patient_suspect_drugs['num_suspect_drugs'] > 1]\n",
        "print(f\"\\n{len(multi_drug_patients):,} patients on multiple suspect drugs\")\n",
        "\n",
        "# Find most common drug pairs\n",
        "print(\"\\nFinding common drug combinations...\")\n",
        "drug_pairs = []\n",
        "for drugs in multi_drug_patients['suspect_drugs'].head(10000):  # Sample for speed\n",
        "    if len(drugs) >= 2:\n",
        "        for i in range(len(drugs)):\n",
        "            for j in range(i+1, len(drugs)):\n",
        "                drug_pairs.append(tuple(sorted([drugs[i], drugs[j]])))\n",
        "\n",
        "from collections import Counter\n",
        "pair_counts = Counter(drug_pairs)\n",
        "print(\"\\nTop 30 drug pairs (potential interactions):\")\n",
        "print(\"=\"*60)\n",
        "for idx, (pair, count) in enumerate(pair_counts.most_common(30), 1):\n",
        "    print(f\"  {idx:2d}. {pair[0]} + {pair[1]}: {count} cases\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpgltPa7i50y",
        "outputId": "9a6efd57-e2e0-44c0-b222-dd9d18642ed9"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Step 3: Analyzing drug patterns...\n",
            "Polypharmacy distribution (suspect drugs):\n",
            "polypharmacy_category\n",
            "monotherapy      329750\n",
            "dual_therapy      36906\n",
            "moderate_poly     27477\n",
            "severe_poly        7873\n",
            "extreme_poly       4141\n",
            "Name: count, dtype: int64\n",
            "\n",
            "76,434 patients on multiple suspect drugs\n",
            "\n",
            "Finding common drug combinations...\n",
            "\n",
            "Top 30 drug pairs (potential interactions):\n",
            "============================================================\n",
            "   1. PREDNISONE + RITUXIMAB: 252 cases\n",
            "   2. METHOTREXATE + RITUXIMAB: 207 cases\n",
            "   3. ACTEMRA + RITUXIMAB: 177 cases\n",
            "   4. METHOTREXATE + PREDNISONE: 174 cases\n",
            "   5. CYCLOPHOSPHAMIDE + RITUXIMAB: 167 cases\n",
            "   6. COSENTYX + METHOTREXATE: 162 cases\n",
            "   7. RISPERDAL + RISPERIDONE: 158 cases\n",
            "   8. LEFLUNOMIDE + METHOTREXATE: 155 cases\n",
            "   9. OPDIVO + YERVOY: 154 cases\n",
            "  10. HUMIRA + METHOTREXATE: 150 cases\n",
            "  11. ENBREL + HUMIRA: 147 cases\n",
            "  12. ACTEMRA + METHOTREXATE: 146 cases\n",
            "  13. ATRIPLA + TRUVADA: 142 cases\n",
            "  14. HUMIRA + REMICADE: 136 cases\n",
            "  15. ENBREL + METHOTREXATE: 132 cases\n",
            "  16. ENBREL + REMICADE: 128 cases\n",
            "  17. CYCLOPHOSPHAMIDE + DEXAMETHASONE: 127 cases\n",
            "  18. ACTEMRA + ORENCIA: 127 cases\n",
            "  19. CYCLOPHOSPHAMIDE + VINCRISTINE: 126 cases\n",
            "  20. METHOTREXATE + SULFASALAZINE: 125 cases\n",
            "  21. ACTEMRA + ENBREL: 124 cases\n",
            "  22. METHOTREXATE + REMICADE: 123 cases\n",
            "  23. MYCOPHENOLATE MOFETIL + TACROLIMUS: 123 cases\n",
            "  24. ENBREL + ORENCIA: 123 cases\n",
            "  25. CYCLOPHOSPHAMIDE + PREDNISONE: 120 cases\n",
            "  26. ACETAMINOPHEN + PREDNISONE: 119 cases\n",
            "  27. TRUVADA + VIREAD: 119 cases\n",
            "  28. HUMIRA + PREDNISONE: 119 cases\n",
            "  29. ACTEMRA + HUMIRA: 118 cases\n",
            "  30. FOLIC ACID + METHOTREXATE: 117 cases\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Demographics Data"
      ],
      "metadata": {
        "id": "ARrpxMo5nvjM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create clean demographics dataframe\n",
        "demo_clean = demo.copy()"
      ],
      "metadata": {
        "id": "TLqCywaSlC-D"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Standardize age to years\n",
        "print(\"1. Standardizing age to years...\")\n",
        "age_conversion = {\n",
        "    'YR': 1,           # Years\n",
        "    'MON': 1/12,       # Months to years\n",
        "    'WK': 1/52,        # Weeks to years\n",
        "    'DY': 1/365,       # Days to years\n",
        "    'DEC': 10,         # Decades to years\n",
        "    'HR': 1/(365*24),  # Hours to years (for newborns)\n",
        "    'YRS': 1           # Alternative years notation\n",
        "}\n",
        "\n",
        "# Create age_years column\n",
        "demo_clean['age_years'] = np.nan\n",
        "for unit, multiplier in age_conversion.items():\n",
        "    mask = demo_clean['age_cod'] == unit\n",
        "    if mask.any():\n",
        "        demo_clean.loc[mask, 'age_years'] = pd.to_numeric(demo_clean.loc[mask, 'age'], errors='coerce') * multiplier\n",
        "        print(f\"  Converted {mask.sum():,} ages from {unit}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnTtksSMn18e",
        "outputId": "b0cc6a88-1b87-4057-cf51-e44e7511a66b"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Standardizing age to years...\n",
            "  Converted 241,545 ages from YR\n",
            "  Converted 1,467 ages from MON\n",
            "  Converted 141 ages from WK\n",
            "  Converted 1,657 ages from DY\n",
            "  Converted 3,591 ages from DEC\n",
            "  Converted 26 ages from HR\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Create age groups for association rules\n",
        "print(\"\\n2. Creating age groups for mining...\")\n",
        "demo_clean['age_group'] = pd.cut(\n",
        "    demo_clean['age_years'],\n",
        "    bins=[0, 2, 12, 18, 45, 65, 80, 150],\n",
        "    labels=['infant', 'child', 'adolescent', 'adult', 'middle_age', 'elderly', 'very_elderly'],\n",
        "    include_lowest=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkwrLU6ln5Wq",
        "outputId": "c975e405-c65e-4b47-83e0-17c8182a3793"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "2. Creating age groups for mining...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Clean sex values\n",
        "print(\"\\n3. Cleaning sex values...\")\n",
        "sex_mapping = {'M': 'Male', 'F': 'Female', 'UNK': 'Unknown', 'U': 'Unknown', np.nan: 'Unknown'}\n",
        "demo_clean['sex_clean'] = demo_clean['sex'].map(sex_mapping).fillna('Unknown')\n",
        "\n",
        "# 4. Country analysis\n",
        "print(\"\\n4. Analyzing reporter countries...\")\n",
        "top_countries = demo_clean['occr_country'].value_counts().head(10)\n",
        "print(\"Top 10 countries by reports:\")\n",
        "for country, count in top_countries.items():\n",
        "    pct = (count/len(demo_clean))*100\n",
        "    print(f\"  {country}: {count:,} ({pct:.1f}%)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udkAYglGn_M0",
        "outputId": "28581718-3b39-4e23-d2fb-b82baf37b71e"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "3. Cleaning sex values...\n",
            "\n",
            "4. Analyzing reporter countries...\n",
            "Top 10 countries by reports:\n",
            "  US: 242,903 (59.8%)\n",
            "  CA: 26,980 (6.6%)\n",
            "  JP: 14,876 (3.7%)\n",
            "  GB: 13,469 (3.3%)\n",
            "  FR: 13,446 (3.3%)\n",
            "  DE: 7,454 (1.8%)\n",
            "  CN: 5,731 (1.4%)\n",
            "  IT: 5,218 (1.3%)\n",
            "  ES: 4,076 (1.0%)\n",
            "  AU: 3,384 (0.8%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Create final demographics features\n",
        "demo_processed = demo_clean[['primaryid', 'age_years', 'age_group', 'sex_clean', 'occr_country']].copy()\n",
        "\n",
        "# Add binary features for association mining\n",
        "demo_processed['is_elderly'] = (demo_processed['age_years'] >= 65).astype(int)\n",
        "demo_processed['is_pediatric'] = (demo_processed['age_years'] < 18).astype(int)\n",
        "#demo_processed['is_female'] = (demo_processed['sex_clean'] == 'Female').astype(int) -- Removing it as it is redundant. we have sex_clean column for that\n",
        "\n",
        "# Summary statistics\n",
        "print(\"\\n\" + \"-\"*40)\n",
        "print(\"Demographics Summary:\")\n",
        "print(f\"  Total patients: {len(demo_processed):,}\")\n",
        "print(f\"  Age available: {demo_processed['age_years'].notna().sum():,} ({(demo_processed['age_years'].notna().sum()/len(demo_processed)*100):.1f}%)\")\n",
        "print(f\"  Mean age: {demo_processed['age_years'].mean():.1f} years\")\n",
        "print(f\"  Median age: {demo_processed['age_years'].median():.1f} years\")\n",
        "print(f\"  Elderly (≥65): {demo_processed['is_elderly'].sum():,} ({(demo_processed['is_elderly'].sum()/len(demo_processed)*100):.1f}%)\")\n",
        "print(f\"  Pediatric (<18): {demo_processed['is_pediatric'].sum():,} ({(demo_processed['is_pediatric'].sum()/len(demo_processed)*100):.1f}%)\")\n",
        "\n",
        "print(\"\\nAge group distribution:\")\n",
        "age_dist = demo_processed['age_group'].value_counts()\n",
        "for group, count in age_dist.items():\n",
        "    pct = (count/len(demo_processed))*100\n",
        "    print(f\"  {group}: {count:,} ({pct:.1f}%)\")\n",
        "\n",
        "print(\"\\nSex distribution:\")\n",
        "sex_dist = demo_processed['sex_clean'].value_counts()\n",
        "for sex, count in sex_dist.items():\n",
        "    pct = (count/len(demo_processed))*100\n",
        "    print(f\"  {sex}: {count:,} ({pct:.1f}%)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLMWl0TCoDqO",
        "outputId": "c44a18e1-bb6d-4dee-9c7d-da9fa2e973c7"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "----------------------------------------\n",
            "Demographics Summary:\n",
            "  Total patients: 406,184\n",
            "  Age available: 248,412 (61.2%)\n",
            "  Mean age: 55.2 years\n",
            "  Median age: 59.0 years\n",
            "  Elderly (≥65): 98,580 (24.3%)\n",
            "  Pediatric (<18): 17,897 (4.4%)\n",
            "\n",
            "Age group distribution:\n",
            "  middle_age: 82,439 (20.3%)\n",
            "  elderly: 73,085 (18.0%)\n",
            "  adult: 53,814 (13.2%)\n",
            "  very_elderly: 20,034 (4.9%)\n",
            "  child: 8,347 (2.1%)\n",
            "  adolescent: 7,820 (1.9%)\n",
            "  infant: 2,870 (0.7%)\n",
            "\n",
            "Sex distribution:\n",
            "  Female: 204,178 (50.3%)\n",
            "  Male: 137,899 (33.9%)\n",
            "  Unknown: 64,107 (15.8%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Reaction Dataset"
      ],
      "metadata": {
        "id": "6LKTxDIHxTJf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean reactions (we already removed duplicates earlier)\n",
        "reac_clean = reac.copy()"
      ],
      "metadata": {
        "id": "L99ouLZIoXDF"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Standardize reaction terms\n",
        "print(\"1. Standardizing reaction terms...\")\n",
        "reac_clean['pt_clean'] = reac_clean['pt'].str.upper().str.strip()\n",
        "\n",
        "# Remove invalid/uninformative reactions\n",
        "invalid_reactions = ['UNKNOWN', 'NA', 'NONE', 'NO ADVERSE EVENT', 'NO ADVERSE DRUG REACTION']\n",
        "before_count = len(reac_clean)\n",
        "reac_clean = reac_clean[~reac_clean['pt_clean'].isin(invalid_reactions)]\n",
        "print(f\"  Removed {before_count - len(reac_clean):,} invalid reaction records\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5_rVCkpxW_Y",
        "outputId": "02c813f6-4c26-4a87-fe15-07317d1326be"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Standardizing reaction terms...\n",
            "  Removed 5,484 invalid reaction records\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Identify serious reactions based on MedDRA preferred terms\n",
        "print(\"\\n2. Identifying serious adverse events...\")\n",
        "serious_keywords = [\n",
        "    'DEATH', 'DIED', 'FATAL',\n",
        "    'CARDIAC ARREST', 'MYOCARDIAL INFARCTION', 'HEART FAILURE',\n",
        "    'STROKE', 'CEREBROVASCULAR', 'HAEMORRHAGE',\n",
        "    'ANAPHYLACTIC', 'STEVENS-JOHNSON', 'TOXIC EPIDERMAL NECROLYSIS',\n",
        "    'HEPATIC FAILURE', 'LIVER FAILURE', 'HEPATOTOXICITY',\n",
        "    'RENAL FAILURE', 'KIDNEY FAILURE',\n",
        "    'RESPIRATORY FAILURE', 'RESPIRATORY ARREST',\n",
        "    'SEPSIS', 'SEPTIC SHOCK',\n",
        "    'SUICIDE', 'OVERDOSE'\n",
        "]\n",
        "\n",
        "# Flag serious reactions\n",
        "reac_clean['is_serious'] = reac_clean['pt_clean'].apply(\n",
        "    lambda x: any(keyword in x for keyword in serious_keywords) if pd.notna(x) else False\n",
        ")\n",
        "\n",
        "print(f\"  Reactions flagged as serious: {reac_clean['is_serious'].sum():,}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXEOZ4B5xZry",
        "outputId": "8bdc204e-7371-4d15-f7f6-bdfc879eec90"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "2. Identifying serious adverse events...\n",
            "  Reactions flagged as serious: 53,982\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Group reactions by patient\n",
        "print(\"\\n3. Creating patient reaction profiles...\")\n",
        "patient_reactions = reac_clean.groupby('primaryid').agg({\n",
        "    'pt_clean': lambda x: list(set(x)),\n",
        "    'is_serious': 'max'\n",
        "}).rename(columns={'pt_clean': 'all_reactions', 'is_serious': 'has_serious_reaction'})\n",
        "\n",
        "patient_reactions['num_reactions'] = patient_reactions['all_reactions'].apply(len)\n",
        "\n",
        "# Create reaction categories\n",
        "patient_reactions['reaction_severity'] = pd.cut(\n",
        "    patient_reactions['num_reactions'],\n",
        "    bins=[0, 1, 3, 5, 10, 100],\n",
        "    labels=['single', 'few', 'moderate', 'many', 'extreme']\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8hwufE6xk0h",
        "outputId": "6bd0ce5f-8773-45ef-8922-6132d602e063"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "3. Creating patient reaction profiles...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Top adverse events analysis\n",
        "print(\"\\n4. Analyzing top adverse events...\")\n",
        "top_reactions = reac_clean['pt_clean'].value_counts().head(30)\n",
        "print(\"Top 30 most reported adverse events:\")\n",
        "print(\"=\"*60)\n",
        "for idx, (reaction, count) in enumerate(top_reactions.items(), 1):\n",
        "    pct = (count/len(reac_clean))*100\n",
        "    serious_flag = \"⚠️ SERIOUS\" if any(kw in reaction for kw in serious_keywords) else \"\"\n",
        "    print(f\"  {idx:2d}. {reaction}: {count:,} ({pct:.2f}%) {serious_flag}\")\n",
        "\n",
        "# 5. Statistics\n",
        "print(\"\\n\" + \"-\"*40)\n",
        "print(\"Reaction Statistics:\")\n",
        "print(f\"  Total reaction records: {len(reac_clean):,}\")\n",
        "print(f\"  Unique adverse events: {reac_clean['pt_clean'].nunique():,}\")\n",
        "print(f\"  Patients with reactions: {len(patient_reactions):,}\")\n",
        "print(f\"  Mean reactions per patient: {patient_reactions['num_reactions'].mean():.2f}\")\n",
        "print(f\"  Median reactions per patient: {patient_reactions['num_reactions'].median():.0f}\")\n",
        "print(f\"  Patients with serious reactions: {patient_reactions['has_serious_reaction'].sum():,} ({(patient_reactions['has_serious_reaction'].sum()/len(patient_reactions)*100):.1f}%)\")\n",
        "\n",
        "print(\"\\nReaction count distribution:\")\n",
        "reaction_dist = patient_reactions['reaction_severity'].value_counts()\n",
        "for severity, count in reaction_dist.items():\n",
        "    pct = (count/len(patient_reactions))*100\n",
        "    print(f\"  {severity}: {count:,} ({pct:.1f}%)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RDjhJJ-xphI",
        "outputId": "9b34b612-ebe2-4db4-a6c4-58f3a291f2e8"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "4. Analyzing top adverse events...\n",
            "Top 30 most reported adverse events:\n",
            "============================================================\n",
            "   1. OFF LABEL USE: 32,627 (2.30%) \n",
            "   2. DRUG INEFFECTIVE: 23,762 (1.68%) \n",
            "   3. FATIGUE: 20,196 (1.42%) \n",
            "   4. NAUSEA: 16,577 (1.17%) \n",
            "   5. DIARRHOEA: 16,301 (1.15%) \n",
            "   6. PRODUCT DOSE OMISSION ISSUE: 16,030 (1.13%) \n",
            "   7. DEATH: 15,906 (1.12%) ⚠️ SERIOUS\n",
            "   8. COVID-19: 13,034 (0.92%) \n",
            "   9. HEADACHE: 12,982 (0.92%) \n",
            "  10. PAIN: 12,794 (0.90%) \n",
            "  11. DYSPNOEA: 11,612 (0.82%) \n",
            "  12. ARTHRALGIA: 11,163 (0.79%) \n",
            "  13. PRURITUS: 10,500 (0.74%) \n",
            "  14. VOMITING: 9,701 (0.68%) \n",
            "  15. RASH: 9,588 (0.68%) \n",
            "  16. DRUG DOSE OMISSION BY DEVICE: 9,577 (0.68%) \n",
            "  17. INAPPROPRIATE SCHEDULE OF PRODUCT ADMINISTRATION: 9,466 (0.67%) \n",
            "  18. DIZZINESS: 9,441 (0.67%) \n",
            "  19. MALAISE: 9,420 (0.66%) \n",
            "  20. CONDITION AGGRAVATED: 8,934 (0.63%) \n",
            "  21. INJECTION SITE PAIN: 8,509 (0.60%) \n",
            "  22. ASTHENIA: 8,501 (0.60%) \n",
            "  23. PNEUMONIA: 8,171 (0.58%) \n",
            "  24. COUGH: 8,140 (0.57%) \n",
            "  25. PYREXIA: 8,076 (0.57%) \n",
            "  26. INCORRECT DOSE ADMINISTERED: 7,868 (0.55%) \n",
            "  27. PRODUCT USE IN UNAPPROVED INDICATION: 7,189 (0.51%) \n",
            "  28. FALL: 7,151 (0.50%) \n",
            "  29. WEIGHT DECREASED: 7,131 (0.50%) \n",
            "  30. ILLNESS: 7,046 (0.50%) \n",
            "\n",
            "----------------------------------------\n",
            "Reaction Statistics:\n",
            "  Total reaction records: 1,417,998\n",
            "  Unique adverse events: 12,360\n",
            "  Patients with reactions: 405,814\n",
            "  Mean reactions per patient: 3.49\n",
            "  Median reactions per patient: 2\n",
            "  Patients with serious reactions: 48,589 (12.0%)\n",
            "\n",
            "Reaction count distribution:\n",
            "  single: 152,634 (37.6%)\n",
            "  few: 145,541 (35.9%)\n",
            "  moderate: 49,367 (12.2%)\n",
            "  many: 37,038 (9.1%)\n",
            "  extreme: 21,097 (5.2%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Outcomes and Indications Dataset"
      ],
      "metadata": {
        "id": "F9P181N6yTIS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PART A: Process Outcomes\n",
        "outc_clean = outc.copy()"
      ],
      "metadata": {
        "id": "NbFbJ7JGyv6m"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Map outcome codes to descriptions\n",
        "outcome_mapping = {\n",
        "    'DE': 'Death',\n",
        "    'LT': 'Life-Threatening',\n",
        "    'HO': 'Hospitalization - Initial or Prolonged',\n",
        "    'DS': 'Disability',\n",
        "    'CA': 'Congenital Anomaly',\n",
        "    'RI': 'Required Intervention to Prevent Permanent Impairment',\n",
        "    'OT': 'Other Serious (Important Medical Event)'\n",
        "}\n",
        "outc_clean['outcome_desc'] = outc_clean['outc_cod'].map(outcome_mapping)\n",
        "\n",
        "\n",
        "\n",
        "# Define serious outcomes\n",
        "serious_outcome_codes = ['DE', 'LT', 'HO', 'DS', 'CA']\n",
        "outc_clean['is_serious_outcome'] = outc_clean['outc_cod'].isin(serious_outcome_codes)\n",
        "\n",
        "print(\"Outcome Distribution:\")\n",
        "for code, desc in outcome_mapping.items():\n",
        "    count = (outc_clean['outc_cod'] == code).sum()\n",
        "    if count > 0:\n",
        "        pct = (count/len(outc_clean))*100\n",
        "        serious = \"⚠️ SERIOUS\" if code in serious_outcome_codes else \"\"\n",
        "        print(f\"  {code} ({desc}): {count:,} ({pct:.1f}%) {serious}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RP2VB-_sxtmf",
        "outputId": "d41f1599-d371-4b73-82f6-7c89d9053727"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outcome Distribution:\n",
            "  DE (Death): 32,303 (10.9%) ⚠️ SERIOUS\n",
            "  LT (Life-Threatening): 11,990 (4.1%) ⚠️ SERIOUS\n",
            "  HO (Hospitalization - Initial or Prolonged): 82,534 (28.0%) ⚠️ SERIOUS\n",
            "  DS (Disability): 6,112 (2.1%) ⚠️ SERIOUS\n",
            "  CA (Congenital Anomaly): 895 (0.3%) ⚠️ SERIOUS\n",
            "  RI (Required Intervention to Prevent Permanent Impairment): 981 (0.3%) \n",
            "  OT (Other Serious (Important Medical Event)): 160,229 (54.3%) \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by patient\n",
        "patient_outcomes = outc_clean.groupby('primaryid').agg({\n",
        "    'outc_cod': lambda x: list(x),\n",
        "    'is_serious_outcome': 'max',\n",
        "    'outcome_desc': lambda x: list(x)\n",
        "}).rename(columns={'outc_cod': 'outcome_codes', 'outcome_desc': 'outcome_descriptions'})\n",
        "\n",
        "print(f\"\\nOutcome Statistics:\")\n",
        "print(f\"  Total patients with outcomes: {len(patient_outcomes):,}\")\n",
        "print(f\"  Patients with serious outcomes: {patient_outcomes['is_serious_outcome'].sum():,} ({(patient_outcomes['is_serious_outcome'].sum()/len(patient_outcomes)*100):.1f}%)\")\n",
        "\n",
        "# Check for death outcomes specifically\n",
        "death_patients = outc_clean[outc_clean['outc_cod'] == 'DE']['primaryid'].nunique()\n",
        "print(f\"  Patients with death outcome: {death_patients:,} ({(death_patients/406184*100):.2f}% of all patients)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuPDcZlnyjLQ",
        "outputId": "f4f1c468-f9b3-4511-84bd-9838fc81bd70"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Outcome Statistics:\n",
            "  Total patients with outcomes: 222,364\n",
            "  Patients with serious outcomes: 115,725 (52.0%)\n",
            "  Patients with death outcome: 32,303 (7.95% of all patients)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PART B: Process Indications\n",
        "\n",
        "indi_clean = indi.copy()"
      ],
      "metadata": {
        "id": "V7ugGp45yk-R"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize indication terms\n",
        "indi_clean['indi_pt_clean'] = indi_clean['indi_pt'].str.upper().str.strip()\n",
        "\n",
        "# Remove invalid indications\n",
        "invalid_indications = ['UNKNOWN', 'UNK', 'PRODUCT USED FOR UNKNOWN INDICATION', 'NA', 'NONE']\n",
        "before_indi = len(indi_clean)\n",
        "indi_clean = indi_clean[~indi_clean['indi_pt_clean'].isin(invalid_indications)]\n",
        "print(f\"Removed {before_indi - len(indi_clean):,} invalid indication records\")\n",
        "\n",
        "# Group by patient\n",
        "patient_indications = indi_clean.groupby('primaryid')['indi_pt_clean'].apply(lambda x: list(set(x))).to_frame()\n",
        "patient_indications.columns = ['indications']\n",
        "patient_indications['num_indications'] = patient_indications['indications'].apply(len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOobctMNyqfq",
        "outputId": "c8cf042a-73f6-4b40-8908-cdf9c4f29c60"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removed 492,799 invalid indication records\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Top indications\n",
        "print(f\"\\nIndication Statistics:\")\n",
        "print(f\"  Total patients with indications: {len(patient_indications):,}\")\n",
        "print(f\"  Mean indications per patient: {patient_indications['num_indications'].mean():.2f}\")\n",
        "\n",
        "top_indications = indi_clean['indi_pt_clean'].value_counts().head(30)\n",
        "print(\"\\nTop 30 Drug Indications (Why drugs were prescribed):\")\n",
        "print(\"=\"*60)\n",
        "for idx, (indication, count) in enumerate(top_indications.items(), 1):\n",
        "    pct = (count/len(indi_clean))*100\n",
        "    print(f\"  {idx:2d}. {indication}: {count:,} ({pct:.2f}%)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIMiJA-4y8AY",
        "outputId": "bfaefc66-d9d0-49a5-ce38-bc277cf0e4da"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Indication Statistics:\n",
            "  Total patients with indications: 290,535\n",
            "  Mean indications per patient: 1.44\n",
            "\n",
            "Top 30 Drug Indications (Why drugs were prescribed):\n",
            "============================================================\n",
            "   1. RHEUMATOID ARTHRITIS: 47,062 (6.79%)\n",
            "   2. TYPE 2 DIABETES MELLITUS: 19,351 (2.79%)\n",
            "   3. PLASMA CELL MYELOMA: 16,479 (2.38%)\n",
            "   4. DERMATITIS ATOPIC: 13,333 (1.92%)\n",
            "   5. ASTHMA: 13,332 (1.92%)\n",
            "   6. CROHN'S DISEASE: 12,096 (1.74%)\n",
            "   7. HYPERTENSION: 11,985 (1.73%)\n",
            "   8. PROPHYLAXIS: 9,765 (1.41%)\n",
            "   9. PSORIASIS: 9,020 (1.30%)\n",
            "  10. COLITIS ULCERATIVE: 9,019 (1.30%)\n",
            "  11. DIABETES MELLITUS: 8,661 (1.25%)\n",
            "  12. PULMONARY ARTERIAL HYPERTENSION: 7,489 (1.08%)\n",
            "  13. PROSTATE CANCER: 7,431 (1.07%)\n",
            "  14. MIGRAINE: 7,394 (1.07%)\n",
            "  15. DIFFUSE LARGE B-CELL LYMPHOMA: 7,163 (1.03%)\n",
            "  16. PAIN: 7,057 (1.02%)\n",
            "  17. PSORIATIC ARTHROPATHY: 6,885 (0.99%)\n",
            "  18. WEIGHT CONTROL: 6,588 (0.95%)\n",
            "  19. MULTIPLE SCLEROSIS: 6,554 (0.95%)\n",
            "  20. ACUTE MYELOID LEUKAEMIA: 5,541 (0.80%)\n",
            "  21. DEPRESSION: 5,273 (0.76%)\n",
            "  22. BREAST CANCER: 5,134 (0.74%)\n",
            "  23. SCHIZOPHRENIA: 5,016 (0.72%)\n",
            "  24. COVID-19 TREATMENT: 4,763 (0.69%)\n",
            "  25. HIV INFECTION: 4,660 (0.67%)\n",
            "  26. PARKINSON'S DISEASE: 4,415 (0.64%)\n",
            "  27. BREAST CANCER METASTATIC: 4,337 (0.63%)\n",
            "  28. PREMEDICATION: 4,007 (0.58%)\n",
            "  29. ILL-DEFINED DISORDER: 3,969 (0.57%)\n",
            "  30. IMMUNOSUPPRESSANT DRUG THERAPY: 3,580 (0.52%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify disease areas\n",
        "print(\"\\n\" + \"-\"*40)\n",
        "print(\"Disease Area Analysis:\")\n",
        "disease_keywords = {\n",
        "    'Cancer': ['CANCER', 'CARCINOMA', 'TUMOUR', 'TUMOR', 'LYMPHOMA', 'LEUKEMIA', 'MELANOMA', 'METASTATIC'],\n",
        "    'Diabetes': ['DIABETES', 'DIABETIC', 'GLUCOSE', 'HYPERGLYCAEMIA'],\n",
        "    'Cardiovascular': ['HYPERTENSION', 'CARDIAC', 'HEART', 'ATRIAL FIBRILLATION', 'MYOCARDIAL'],\n",
        "    'Psychiatric': ['DEPRESSION', 'ANXIETY', 'PSYCHOTIC', 'BIPOLAR', 'SCHIZOPHRENIA'],\n",
        "    'Autoimmune': ['RHEUMATOID ARTHRITIS', 'LUPUS', 'CROHN', 'COLITIS', 'PSORIASIS'],\n",
        "    'Infection': ['COVID', 'INFECTION', 'HEPATITIS', 'HIV', 'SEPSIS']\n",
        "}\n",
        "\n",
        "for area, keywords in disease_keywords.items():\n",
        "    area_count = indi_clean[indi_clean['indi_pt_clean'].str.contains('|'.join(keywords))]['primaryid'].nunique()\n",
        "    print(f\"  {area}: {area_count:,} patients ({(area_count/406184*100):.1f}%)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6GcmGqmzQ-W",
        "outputId": "72ce49e2-623d-4a87-f5e7-046e4d2ff826"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "----------------------------------------\n",
            "Disease Area Analysis:\n",
            "  Cancer: 42,258 patients (10.4%)\n",
            "  Diabetes: 13,923 patients (3.4%)\n",
            "  Cardiovascular: 16,602 patients (4.1%)\n",
            "  Psychiatric: 9,817 patients (2.4%)\n",
            "  Autoimmune: 39,023 patients (9.6%)\n",
            "  Infection: 15,381 patients (3.8%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Final Data Merge"
      ],
      "metadata": {
        "id": "GNptqU91z8Ww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Start with demographics as base\n",
        "\n",
        "merged_data = demo_processed.copy()\n",
        "print(f\"Base: {merged_data.shape[0]:,} patients from demographics\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aC6R9eN3zUcA",
        "outputId": "ff505452-b61d-4231-a151-ab4ca2096406"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Base: 406,184 patients from demographics\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Merge drug data\n",
        "print(\"\\n1. Merging drug profiles...\")\n",
        "merged_data = merged_data.merge(\n",
        "    patient_suspect_drugs[['suspect_drugs', 'num_suspect_drugs', 'polypharmacy_category']],\n",
        "    left_on='primaryid',\n",
        "    right_index=True,\n",
        "    how='left'\n",
        ")\n",
        "# Also merge concomitant drugs if exists\n",
        "if 'patient_concom_drugs' in locals():\n",
        "    merged_data = merged_data.merge(\n",
        "        patient_concom_drugs[['concomitant_drugs', 'num_concom_drugs']],\n",
        "        left_on='primaryid',\n",
        "        right_index=True,\n",
        "        how='left'\n",
        "    )\n",
        "print(f\"After drug merge: {merged_data.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5JP-iLa0Bl8",
        "outputId": "aacb8a8d-d567-4ebe-9e2f-7a7a853f7b94"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "1. Merging drug profiles...\n",
            "After drug merge: (406184, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Merge reactions\n",
        "print(\"2. Merging reaction profiles...\")\n",
        "merged_data = merged_data.merge(\n",
        "    patient_reactions[['all_reactions', 'num_reactions', 'has_serious_reaction', 'reaction_severity']],\n",
        "    left_on='primaryid',\n",
        "    right_index=True,\n",
        "    how='left'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VP2v-X1G0G7l",
        "outputId": "b565ab29-d716-4438-b189-f4c42b6d81e4"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2. Merging reaction profiles...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"After reaction merge: {merged_data.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8odmD-fq0Kwg",
        "outputId": "65e812c7-ba7d-4648-8046-9b739cf499fc"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After reaction merge: (406184, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Merge outcomes\n",
        "print(\"3. Merging outcome data...\")\n",
        "merged_data = merged_data.merge(\n",
        "    patient_outcomes[['outcome_codes', 'is_serious_outcome', 'outcome_descriptions']],\n",
        "    left_on='primaryid',\n",
        "    right_index=True,\n",
        "    how='left'\n",
        ")\n",
        "print(f\"After outcome merge: {merged_data.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4tO_QPO0Nlr",
        "outputId": "800909ab-be71-4c77-a78f-c1c01bf4602e"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3. Merging outcome data...\n",
            "After outcome merge: (406184, 19)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Merge indications\n",
        "print(\"4. Merging indication data...\")\n",
        "merged_data = merged_data.merge(\n",
        "    patient_indications[['indications', 'num_indications']],\n",
        "    left_on='primaryid',\n",
        "    right_index=True,\n",
        "    how='left'\n",
        ")\n",
        "print(f\"After indication merge: {merged_data.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prRhYaE70RJK",
        "outputId": "dff17986-e79d-4272-8cb9-3b87413869b9"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4. Merging indication data...\n",
            "After indication merge: (406184, 21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Quality check - remove patients with no drugs or no reactions\n",
        "print(\"\\n5. Data quality filtering...\")\n",
        "before_filter = len(merged_data)\n",
        "\n",
        "# Must have at least drugs and reactions for meaningful analysis\n",
        "has_drugs = merged_data['suspect_drugs'].notna()\n",
        "has_reactions = merged_data['all_reactions'].notna()\n",
        "valid_cases = has_drugs & has_reactions\n",
        "\n",
        "merged_data = merged_data[valid_cases].copy()\n",
        "print(f\"Removed {before_filter - len(merged_data):,} incomplete cases\")\n",
        "print(f\"Final dataset: {merged_data.shape[0]:,} complete cases with {merged_data.shape[1]} features\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsF6poUQ0Vnq",
        "outputId": "cd4e10cb-baf8-4778-8364-075a43013596"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "5. Data quality filtering...\n",
            "Removed 370 incomplete cases\n",
            "Final dataset: 405,814 complete cases with 21 features\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Dataset summary\n",
        "\n",
        "print(\"FINAL MERGED DATASET SUMMARY\")\n",
        "for col in merged_data.columns:\n",
        "    if col != 'primaryid':\n",
        "        non_null = merged_data[col].notna().sum()\n",
        "        pct = (non_null / len(merged_data)) * 100\n",
        "        print(f\"  {col}: {non_null:,} ({pct:.1f}%)\")\n",
        "\n",
        "print(\"\\nKey Statistics:\")\n",
        "print(f\"  Total cases: {len(merged_data):,}\")\n",
        "print(f\"  Cases with serious reactions: {merged_data['has_serious_reaction'].sum():,}\")\n",
        "print(f\"  Cases with serious outcomes: {merged_data['is_serious_outcome'].fillna(False).sum():,}\")\n",
        "print(f\"  Cases with both serious reactions AND outcomes: {(merged_data['has_serious_reaction'] & merged_data['is_serious_outcome'].fillna(False)).sum():,}\")\n",
        "print(f\"  Elderly patients (≥65): {merged_data['is_elderly'].sum():,}\")\n",
        "print(f\"  Polypharmacy cases (≥5 drugs): {(merged_data['num_suspect_drugs'] >= 5).sum():,}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yaa2Js-h0cOj",
        "outputId": "70db96ce-03e5-4cbc-ee7e-ccd393fe4265"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FINAL MERGED DATASET SUMMARY\n",
            "  age_years: 248,233 (61.2%)\n",
            "  age_group: 248,230 (61.2%)\n",
            "  sex_clean: 405,814 (100.0%)\n",
            "  occr_country: 368,173 (90.7%)\n",
            "  is_elderly: 405,814 (100.0%)\n",
            "  is_pediatric: 405,814 (100.0%)\n",
            "  suspect_drugs: 405,814 (100.0%)\n",
            "  num_suspect_drugs: 405,814 (100.0%)\n",
            "  polypharmacy_category: 405,777 (100.0%)\n",
            "  concomitant_drugs: 109,890 (27.1%)\n",
            "  num_concom_drugs: 109,890 (27.1%)\n",
            "  all_reactions: 405,814 (100.0%)\n",
            "  num_reactions: 405,814 (100.0%)\n",
            "  has_serious_reaction: 405,814 (100.0%)\n",
            "  reaction_severity: 405,677 (100.0%)\n",
            "  outcome_codes: 222,355 (54.8%)\n",
            "  is_serious_outcome: 222,355 (54.8%)\n",
            "  outcome_descriptions: 222,355 (54.8%)\n",
            "  indications: 290,333 (71.5%)\n",
            "  num_indications: 290,333 (71.5%)\n",
            "\n",
            "Key Statistics:\n",
            "  Total cases: 405,814\n",
            "  Cases with serious reactions: 48,589\n",
            "  Cases with serious outcomes: 115,725\n",
            "  Cases with both serious reactions AND outcomes: 35,069\n",
            "  Elderly patients (≥65): 98,528\n",
            "  Polypharmacy cases (≥5 drugs): 16,506\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merged_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "id": "W8qt2-te0tgK",
        "outputId": "dbf14199-ac24-485a-f9da-54fb89a9cc66"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    primaryid  age_years   age_group sex_clean occr_country  is_elderly  \\\n",
              "0  1001678125       56.0  middle_age    Female           CA           0   \n",
              "1  1002872124       57.0  middle_age    Female           CA           0   \n",
              "2   100293663       32.0       adult      Male           AU           0   \n",
              "3  1005450710       68.0     elderly    Female           US           1   \n",
              "4  1005762118       57.0  middle_age      Male           CA           0   \n",
              "\n",
              "   is_pediatric                                      suspect_drugs  \\\n",
              "0             0               [SANDOSTATIN LAR DEPOT, SANDOSTATIN]   \n",
              "1             0     [SANDOSTATIN LAR DEPOT, AFINITOR, SANDOSTATIN]   \n",
              "2             0  [CYCLOSPORINE, BASILIXIMAB, MYCOPHENOLATE MOFE...   \n",
              "3             0                      [ENBREL, METHOTREXATE SODIUM]   \n",
              "4             0                                   [EXELON, XOLAIR]   \n",
              "\n",
              "   num_suspect_drugs polypharmacy_category  ... num_concom_drugs  \\\n",
              "0                  2          dual_therapy  ...             11.0   \n",
              "1                  3         moderate_poly  ...              4.0   \n",
              "2                  4         moderate_poly  ...              NaN   \n",
              "3                  2          dual_therapy  ...              7.0   \n",
              "4                  2          dual_therapy  ...              9.0   \n",
              "\n",
              "                                       all_reactions num_reactions  \\\n",
              "0  [BLOOD CREATINE INCREASED, FALL, SINUSITIS, SK...          76.0   \n",
              "1  [PNEUMONITIS, ABDOMINAL PAIN UPPER, CARCINOID ...          24.0   \n",
              "2  [STAPHYLOCOCCAL INFECTION, MYCOBACTERIUM HAEMO...           4.0   \n",
              "3             [DRUG HYPERSENSITIVITY, DRUG ERUPTION]           2.0   \n",
              "4  [PHOTOSENSITIVITY REACTION, PARKINSON'S DISEAS...          32.0   \n",
              "\n",
              "   has_serious_reaction reaction_severity outcome_codes is_serious_outcome  \\\n",
              "0                  True           extreme          [OT]              False   \n",
              "1                  True           extreme      [OT, HO]               True   \n",
              "2                 False          moderate          [OT]              False   \n",
              "3                 False               few           NaN                NaN   \n",
              "4                 False           extreme          [HO]               True   \n",
              "\n",
              "                                outcome_descriptions  \\\n",
              "0          [Other Serious (Important Medical Event)]   \n",
              "1  [Other Serious (Important Medical Event), Hosp...   \n",
              "2          [Other Serious (Important Medical Event)]   \n",
              "3                                                NaN   \n",
              "4           [Hospitalization - Initial or Prolonged]   \n",
              "\n",
              "                                         indications num_indications  \n",
              "0                            [NEUROENDOCRINE TUMOUR]             1.0  \n",
              "1  [PANCREATIC NEUROENDOCRINE TUMOUR, CARCINOID T...             2.0  \n",
              "2  [RENAL TRANSPLANT, IMMUNOSUPPRESSANT DRUG THER...             2.0  \n",
              "3                                                NaN             NaN  \n",
              "4                   [ANTIBIOTIC PROPHYLAXIS, ASTHMA]             2.0  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bdd8e6c3-e24d-4c86-95d4-41a959003b32\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>primaryid</th>\n",
              "      <th>age_years</th>\n",
              "      <th>age_group</th>\n",
              "      <th>sex_clean</th>\n",
              "      <th>occr_country</th>\n",
              "      <th>is_elderly</th>\n",
              "      <th>is_pediatric</th>\n",
              "      <th>suspect_drugs</th>\n",
              "      <th>num_suspect_drugs</th>\n",
              "      <th>polypharmacy_category</th>\n",
              "      <th>...</th>\n",
              "      <th>num_concom_drugs</th>\n",
              "      <th>all_reactions</th>\n",
              "      <th>num_reactions</th>\n",
              "      <th>has_serious_reaction</th>\n",
              "      <th>reaction_severity</th>\n",
              "      <th>outcome_codes</th>\n",
              "      <th>is_serious_outcome</th>\n",
              "      <th>outcome_descriptions</th>\n",
              "      <th>indications</th>\n",
              "      <th>num_indications</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1001678125</td>\n",
              "      <td>56.0</td>\n",
              "      <td>middle_age</td>\n",
              "      <td>Female</td>\n",
              "      <td>CA</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[SANDOSTATIN LAR DEPOT, SANDOSTATIN]</td>\n",
              "      <td>2</td>\n",
              "      <td>dual_therapy</td>\n",
              "      <td>...</td>\n",
              "      <td>11.0</td>\n",
              "      <td>[BLOOD CREATINE INCREASED, FALL, SINUSITIS, SK...</td>\n",
              "      <td>76.0</td>\n",
              "      <td>True</td>\n",
              "      <td>extreme</td>\n",
              "      <td>[OT]</td>\n",
              "      <td>False</td>\n",
              "      <td>[Other Serious (Important Medical Event)]</td>\n",
              "      <td>[NEUROENDOCRINE TUMOUR]</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1002872124</td>\n",
              "      <td>57.0</td>\n",
              "      <td>middle_age</td>\n",
              "      <td>Female</td>\n",
              "      <td>CA</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[SANDOSTATIN LAR DEPOT, AFINITOR, SANDOSTATIN]</td>\n",
              "      <td>3</td>\n",
              "      <td>moderate_poly</td>\n",
              "      <td>...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>[PNEUMONITIS, ABDOMINAL PAIN UPPER, CARCINOID ...</td>\n",
              "      <td>24.0</td>\n",
              "      <td>True</td>\n",
              "      <td>extreme</td>\n",
              "      <td>[OT, HO]</td>\n",
              "      <td>True</td>\n",
              "      <td>[Other Serious (Important Medical Event), Hosp...</td>\n",
              "      <td>[PANCREATIC NEUROENDOCRINE TUMOUR, CARCINOID T...</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100293663</td>\n",
              "      <td>32.0</td>\n",
              "      <td>adult</td>\n",
              "      <td>Male</td>\n",
              "      <td>AU</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[CYCLOSPORINE, BASILIXIMAB, MYCOPHENOLATE MOFE...</td>\n",
              "      <td>4</td>\n",
              "      <td>moderate_poly</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[STAPHYLOCOCCAL INFECTION, MYCOBACTERIUM HAEMO...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>False</td>\n",
              "      <td>moderate</td>\n",
              "      <td>[OT]</td>\n",
              "      <td>False</td>\n",
              "      <td>[Other Serious (Important Medical Event)]</td>\n",
              "      <td>[RENAL TRANSPLANT, IMMUNOSUPPRESSANT DRUG THER...</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1005450710</td>\n",
              "      <td>68.0</td>\n",
              "      <td>elderly</td>\n",
              "      <td>Female</td>\n",
              "      <td>US</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>[ENBREL, METHOTREXATE SODIUM]</td>\n",
              "      <td>2</td>\n",
              "      <td>dual_therapy</td>\n",
              "      <td>...</td>\n",
              "      <td>7.0</td>\n",
              "      <td>[DRUG HYPERSENSITIVITY, DRUG ERUPTION]</td>\n",
              "      <td>2.0</td>\n",
              "      <td>False</td>\n",
              "      <td>few</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1005762118</td>\n",
              "      <td>57.0</td>\n",
              "      <td>middle_age</td>\n",
              "      <td>Male</td>\n",
              "      <td>CA</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[EXELON, XOLAIR]</td>\n",
              "      <td>2</td>\n",
              "      <td>dual_therapy</td>\n",
              "      <td>...</td>\n",
              "      <td>9.0</td>\n",
              "      <td>[PHOTOSENSITIVITY REACTION, PARKINSON'S DISEAS...</td>\n",
              "      <td>32.0</td>\n",
              "      <td>False</td>\n",
              "      <td>extreme</td>\n",
              "      <td>[HO]</td>\n",
              "      <td>True</td>\n",
              "      <td>[Hospitalization - Initial or Prolonged]</td>\n",
              "      <td>[ANTIBIOTIC PROPHYLAXIS, ASTHMA]</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bdd8e6c3-e24d-4c86-95d4-41a959003b32')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bdd8e6c3-e24d-4c86-95d4-41a959003b32 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bdd8e6c3-e24d-4c86-95d4-41a959003b32');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-891236b1-a7b0-4a90-b220-ceb19b4e80e6\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-891236b1-a7b0-4a90-b220-ceb19b4e80e6')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-891236b1-a7b0-4a90-b220-ceb19b4e80e6 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "merged_data"
            }
          },
          "metadata": {},
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merged_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Scn_NYk1xsQ",
        "outputId": "6432192f-0b34-470b-d0b7-926e2319a248"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(405814, 21)"
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merged_data.memory_usage(deep=True).sum() / (1024**2)   # in MB"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af6bMT9j11f7",
        "outputId": "ae1a9d16-684b-4589-9c46-94a0a5be2ab4"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(259.0941114425659)"
            ]
          },
          "metadata": {},
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Save the processed Q1 file to drive"
      ],
      "metadata": {
        "id": "NYZxnoaD6u_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_path = '/content/drive/MyDrive/Dataset/processed_quarters/'\n",
        "os.makedirs(output_path, exist_ok=True)"
      ],
      "metadata": {
        "id": "8WxSWf8p3m6j"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Saving Q1 processed data...\")\n",
        "print(f\"Q1 shape: {merged_data.shape}\")\n",
        "merged_data.to_pickle(f'{output_path}processed_2024Q1.pkl')\n",
        "print(f\"✓ Saved Q1 to: {output_path}processed_2024Q1.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8MiMivH7tdm",
        "outputId": "74871217-0d59-4ef6-9cea-6ab114c0a39a"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Q1 processed data...\n",
            "Q1 shape: (405814, 21)\n",
            "✓ Saved Q1 to: /content/drive/MyDrive/Dataset/processed_quarters/processed_2024Q1.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Now we got the logic to process a quarter data towards our goal. So now we are creating a pipeline to process all other quarter data."
      ],
      "metadata": {
        "id": "s-GbovL48Aos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import zipfile\n",
        "import os\n",
        "import warnings\n",
        "import json\n",
        "from datetime import datetime\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def process_quarter(quarter_name, zip_path, output_path, verbose=True):\n",
        "    \"\"\"\n",
        "    Complete pipeline to process one quarter of FAERS data with quality checks\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    quarter_name: str, e.g., '2024Q1', '2024Q2'\n",
        "    zip_path: str, path to the zip file\n",
        "    output_path: str, where to save processed data\n",
        "    verbose: bool, whether to print progress messages\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    tuple: (merged_data, quality_report)\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize quality report\n",
        "    quality_report = {\n",
        "        'quarter': quarter_name,\n",
        "        'processing_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
        "        'issues_found': [],\n",
        "        'data_quality_metrics': {},\n",
        "        'processing_steps': []\n",
        "    }\n",
        "\n",
        "    def log_step(message, data=None):\n",
        "        \"\"\"Helper function to log steps\"\"\"\n",
        "        if verbose:\n",
        "            print(message)\n",
        "        quality_report['processing_steps'].append({\n",
        "            'step': message,\n",
        "            'timestamp': datetime.now().strftime('%H:%M:%S'),\n",
        "            'data': data\n",
        "        })\n",
        "\n",
        "    try:\n",
        "        # ============= STEP 1: EXTRACT ZIP =============\n",
        "        extract_path = f'/content/{quarter_name}/'\n",
        "        os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "        log_step(f\"\\n{'='*60}\")\n",
        "        log_step(f\"PROCESSING {quarter_name}\")\n",
        "        log_step(f\"{'='*60}\")\n",
        "        log_step(f\"1. Extracting {zip_path}...\")\n",
        "\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(extract_path)\n",
        "\n",
        "        # Find ASCII folder\n",
        "        ascii_folder = None\n",
        "        for root, dirs, files in os.walk(extract_path):\n",
        "            if any(file.endswith('.txt') for file in files):\n",
        "                ascii_folder = root\n",
        "                break\n",
        "\n",
        "        if not ascii_folder:\n",
        "            raise ValueError(f\"No ASCII files found in {extract_path}\")\n",
        "\n",
        "        log_step(f\"   ASCII files found in: {ascii_folder}\")\n",
        "\n",
        "        # ============= STEP 2: LOAD DATA FILES =============\n",
        "        log_step(f\"\\n2. Loading data files...\")\n",
        "\n",
        "        # Determine file suffix (24Q1, 24Q2, etc.)\n",
        "        year_suffix = quarter_name.replace('20', '')  # 2024Q1 -> 24Q1\n",
        "\n",
        "        # Load all required files with error handling\n",
        "        data_files = {}\n",
        "        file_sizes = {}\n",
        "\n",
        "        for file_type in ['DEMO', 'DRUG', 'REAC', 'OUTC', 'INDI']:\n",
        "            file_name = f'{file_type}{year_suffix}.txt'\n",
        "            file_path = os.path.join(ascii_folder, file_name)\n",
        "\n",
        "            if os.path.exists(file_path):\n",
        "                try:\n",
        "                    data_files[file_type] = pd.read_csv(\n",
        "                        file_path,\n",
        "                        sep='$',\n",
        "                        encoding='latin-1',\n",
        "                        low_memory=False\n",
        "                    )\n",
        "                    file_sizes[file_type] = data_files[file_type].shape[0]\n",
        "                    log_step(f\"   {file_type}: {file_sizes[file_type]:,} records\")\n",
        "                except Exception as e:\n",
        "                    quality_report['issues_found'].append(f\"Failed to load {file_type}: {str(e)}\")\n",
        "                    raise\n",
        "            else:\n",
        "                quality_report['issues_found'].append(f\"Missing file: {file_name}\")\n",
        "                raise FileNotFoundError(f\"Required file {file_name} not found\")\n",
        "\n",
        "        # Unpack loaded dataframes\n",
        "        demo = data_files['DEMO']\n",
        "        drug = data_files['DRUG']\n",
        "        reac = data_files['REAC']\n",
        "        outc = data_files['OUTC']\n",
        "        indi = data_files['INDI']\n",
        "\n",
        "        # ============= STEP 3: DATA QUALITY CHECKS =============\n",
        "        log_step(f\"\\n3. Running data quality checks...\")\n",
        "\n",
        "        # Check for missing primary IDs\n",
        "        missing_ids = {}\n",
        "        for name, df in data_files.items():\n",
        "            missing_count = df['primaryid'].isna().sum()\n",
        "            missing_ids[name] = missing_count\n",
        "            if missing_count > 0:\n",
        "                quality_report['issues_found'].append(f\"{name} has {missing_count} missing primary IDs\")\n",
        "\n",
        "        quality_report['data_quality_metrics']['missing_primary_ids'] = missing_ids\n",
        "\n",
        "        # ============= STEP 4: HANDLE DUPLICATES =============\n",
        "        log_step(f\"\\n4. Handling duplicates...\")\n",
        "\n",
        "        # Check and remove DRUG duplicates\n",
        "        drug_dup_count = drug[['primaryid', 'drug_seq']].duplicated().sum()\n",
        "        if drug_dup_count > 0:\n",
        "            drug = drug.drop_duplicates(subset=['primaryid', 'drug_seq'], keep='first')\n",
        "            log_step(f\"   Removed {drug_dup_count} duplicate drug records\")\n",
        "            quality_report['data_quality_metrics']['drug_duplicates_removed'] = drug_dup_count\n",
        "\n",
        "        # Check and remove REAC duplicates\n",
        "        reac_dup_count = reac[['primaryid', 'pt']].duplicated().sum()\n",
        "        if reac_dup_count > 0:\n",
        "            reac = reac.drop_duplicates(subset=['primaryid', 'pt'], keep='first')\n",
        "            log_step(f\"   Removed {reac_dup_count} duplicate reaction records\")\n",
        "            quality_report['data_quality_metrics']['reac_duplicates_removed'] = reac_dup_count\n",
        "\n",
        "        # ============= STEP 5: PROCESS DEMOGRAPHICS =============\n",
        "        log_step(f\"\\n5. Processing demographics...\")\n",
        "        demo_clean = demo.copy()\n",
        "\n",
        "        # Standardize age to years\n",
        "        age_conversion = {\n",
        "            'YR': 1, 'YRS': 1, 'MON': 1/12, 'WK': 1/52,\n",
        "            'DY': 1/365, 'DEC': 10, 'HR': 1/(365*24)\n",
        "        }\n",
        "\n",
        "        demo_clean['age_years'] = np.nan\n",
        "        age_converted_counts = {}\n",
        "\n",
        "        for unit, multiplier in age_conversion.items():\n",
        "            mask = demo_clean['age_cod'] == unit\n",
        "            if mask.any():\n",
        "                count = mask.sum()\n",
        "                demo_clean.loc[mask, 'age_years'] = pd.to_numeric(\n",
        "                    demo_clean.loc[mask, 'age'], errors='coerce'\n",
        "                ) * multiplier\n",
        "                age_converted_counts[unit] = count\n",
        "\n",
        "        quality_report['data_quality_metrics']['age_conversions'] = age_converted_counts\n",
        "\n",
        "        # Create age groups\n",
        "        demo_clean['age_group'] = pd.cut(\n",
        "            demo_clean['age_years'],\n",
        "            bins=[0, 2, 12, 18, 45, 65, 80, 150],\n",
        "            labels=['infant', 'child', 'adolescent', 'adult', 'middle_age', 'elderly', 'very_elderly'],\n",
        "            include_lowest=True\n",
        "        )\n",
        "\n",
        "        # Clean sex values\n",
        "        sex_mapping = {\n",
        "            'M': 'Male', 'F': 'Female',\n",
        "            'UNK': 'Unknown', 'U': 'Unknown',\n",
        "            np.nan: 'Unknown'\n",
        "        }\n",
        "        demo_clean['sex_clean'] = demo_clean['sex'].map(sex_mapping).fillna('Unknown')\n",
        "\n",
        "        # Create binary features\n",
        "        demo_clean['is_elderly'] = (demo_clean['age_years'] >= 65).astype(int)\n",
        "        demo_clean['is_pediatric'] = (demo_clean['age_years'] < 18).astype(int)\n",
        "        #demo_clean['is_female'] = (demo_clean['sex_clean'] == 'Female').astype(int)\n",
        "\n",
        "        # Select final columns\n",
        "        demo_processed = demo_clean[[\n",
        "            'primaryid', 'age_years', 'age_group', 'sex_clean',\n",
        "            'occr_country', 'is_elderly', 'is_pediatric',\n",
        "        ]].copy()\n",
        "\n",
        "        # ============= STEP 6: PROCESS DRUGS =============\n",
        "        log_step(f\"\\n6. Processing drugs...\")\n",
        "\n",
        "        # Process suspect drugs\n",
        "        suspect_drugs = drug[drug['role_cod'].isin(['PS', 'SS', 'I'])].copy()\n",
        "        suspect_drugs['drugname_clean'] = suspect_drugs['drugname'].str.upper().str.strip()\n",
        "\n",
        "        # Remove invalid drug names\n",
        "        invalid_names = [\n",
        "            'UNKNOWN', 'UNK', 'NULL', 'NA', 'N/A',\n",
        "            'NOT SPECIFIED', 'UNSPECIFIED', 'BLINDED'\n",
        "        ]\n",
        "        invalid_drug_count = suspect_drugs['drugname_clean'].isin(invalid_names).sum()\n",
        "        suspect_drugs = suspect_drugs[~suspect_drugs['drugname_clean'].isin(invalid_names)]\n",
        "\n",
        "        if invalid_drug_count > 0:\n",
        "            quality_report['data_quality_metrics']['invalid_drugs_removed'] = invalid_drug_count\n",
        "\n",
        "        # Process concomitant drugs\n",
        "        concomitant_drugs = drug[drug['role_cod'] == 'C'].copy()\n",
        "        concomitant_drugs['drugname_clean'] = concomitant_drugs['drugname'].str.upper().str.strip()\n",
        "        concomitant_drugs = concomitant_drugs[~concomitant_drugs['drugname_clean'].isin(invalid_names)]\n",
        "\n",
        "        # Create patient drug profiles\n",
        "        patient_suspect_drugs = suspect_drugs.groupby('primaryid')['drugname_clean'].apply(\n",
        "            lambda x: list(set(x))\n",
        "        ).to_frame()\n",
        "        patient_suspect_drugs.columns = ['suspect_drugs']\n",
        "        patient_suspect_drugs['num_suspect_drugs'] = patient_suspect_drugs['suspect_drugs'].apply(len)\n",
        "\n",
        "        # Polypharmacy categories\n",
        "        patient_suspect_drugs['polypharmacy_category'] = pd.cut(\n",
        "            patient_suspect_drugs['num_suspect_drugs'],\n",
        "            bins=[0, 1, 2, 5, 10, 1000],\n",
        "            labels=['monotherapy', 'dual_therapy', 'moderate_poly', 'severe_poly', 'extreme_poly']\n",
        "        )\n",
        "\n",
        "        # Concomitant drugs\n",
        "        patient_concom_drugs = concomitant_drugs.groupby('primaryid')['drugname_clean'].apply(\n",
        "            lambda x: list(set(x))\n",
        "        ).to_frame()\n",
        "        patient_concom_drugs.columns = ['concomitant_drugs']\n",
        "        patient_concom_drugs['num_concom_drugs'] = patient_concom_drugs['concomitant_drugs'].apply(len)\n",
        "\n",
        "        patient_suspect_drugs['is_interaction_case'] = (patient_suspect_drugs['num_suspect_drugs'] > 1).astype(int)\n",
        "\n",
        "        primary_drug = suspect_drugs[suspect_drugs['role_cod'] == 'PS'].groupby('primaryid')['drugname_clean'].first()\n",
        "        patient_suspect_drugs['primary_drug'] = patient_suspect_drugs.index.map(primary_drug)\n",
        "\n",
        "        # ============= STEP 7: PROCESS REACTIONS =============\n",
        "        log_step(f\"\\n7. Processing reactions...\")\n",
        "        reac_clean = reac.copy()\n",
        "        reac_clean['pt_clean'] = reac_clean['pt'].str.upper().str.strip()\n",
        "\n",
        "        # Remove invalid reactions\n",
        "        invalid_reactions = ['UNKNOWN', 'NA', 'NONE', 'NO ADVERSE EVENT', 'NO ADVERSE DRUG REACTION']\n",
        "        invalid_reac_count = reac_clean['pt_clean'].isin(invalid_reactions).sum()\n",
        "        reac_clean = reac_clean[~reac_clean['pt_clean'].isin(invalid_reactions)]\n",
        "\n",
        "        if invalid_reac_count > 0:\n",
        "            quality_report['data_quality_metrics']['invalid_reactions_removed'] = invalid_reac_count\n",
        "\n",
        "        # Identify serious reactions\n",
        "        serious_keywords = [\n",
        "            'DEATH', 'DIED', 'FATAL', 'CARDIAC ARREST', 'MYOCARDIAL INFARCTION',\n",
        "            'STROKE', 'ANAPHYLACTIC', 'HEPATIC FAILURE', 'RENAL FAILURE',\n",
        "            'RESPIRATORY FAILURE', 'SEPSIS', 'SEPTIC SHOCK', 'SUICIDE'\n",
        "        ]\n",
        "\n",
        "        reac_clean['is_serious'] = reac_clean['pt_clean'].apply(\n",
        "            lambda x: any(keyword in x for keyword in serious_keywords) if pd.notna(x) else False\n",
        "        )\n",
        "\n",
        "        # Patient reaction profiles\n",
        "        patient_reactions = reac_clean.groupby('primaryid').agg({\n",
        "            'pt_clean': lambda x: list(set(x)),\n",
        "            'is_serious': 'max'\n",
        "        }).rename(columns={'pt_clean': 'all_reactions', 'is_serious': 'has_serious_reaction'})\n",
        "\n",
        "        patient_reactions['num_reactions'] = patient_reactions['all_reactions'].apply(len)\n",
        "        patient_reactions['reaction_severity'] = pd.cut(\n",
        "            patient_reactions['num_reactions'],\n",
        "            bins=[0, 1, 3, 5, 10, 1000],\n",
        "            labels=['single', 'few', 'moderate', 'many', 'extreme']\n",
        "        )\n",
        "\n",
        "        # ============= STEP 8: PROCESS OUTCOMES =============\n",
        "        log_step(f\"\\n8. Processing outcomes...\")\n",
        "\n",
        "        serious_outcome_codes = ['DE', 'LT', 'HO', 'DS', 'CA']\n",
        "        outc['is_serious_outcome'] = outc['outc_cod'].isin(serious_outcome_codes)\n",
        "\n",
        "        outcome_mapping = {\n",
        "            'DE': 'Death', 'LT': 'Life-Threatening', 'HO': 'Hospitalization',\n",
        "            'DS': 'Disability', 'CA': 'Congenital Anomaly',\n",
        "            'RI': 'Required Intervention', 'OT': 'Other Serious'\n",
        "        }\n",
        "        outc['outcome_desc'] = outc['outc_cod'].map(outcome_mapping)\n",
        "\n",
        "        patient_outcomes = outc.groupby('primaryid').agg({\n",
        "            'outc_cod': lambda x: list(x),\n",
        "            'is_serious_outcome': 'max',\n",
        "            'outcome_desc': lambda x: list(x)\n",
        "        }).rename(columns={'outc_cod': 'outcome_codes', 'outcome_desc': 'outcome_descriptions'})\n",
        "\n",
        "        # ============= STEP 9: PROCESS INDICATIONS =============\n",
        "        log_step(f\"\\n9. Processing indications...\")\n",
        "\n",
        "        indi_clean = indi.copy()\n",
        "        indi_clean['indi_pt_clean'] = indi_clean['indi_pt'].str.upper().str.strip()\n",
        "\n",
        "        invalid_indications = ['UNKNOWN', 'UNK', 'PRODUCT USED FOR UNKNOWN INDICATION', 'NA', 'NONE']\n",
        "        invalid_indi_count = indi_clean['indi_pt_clean'].isin(invalid_indications).sum()\n",
        "        indi_clean = indi_clean[~indi_clean['indi_pt_clean'].isin(invalid_indications)]\n",
        "\n",
        "        if invalid_indi_count > 0:\n",
        "            quality_report['data_quality_metrics']['invalid_indications_removed'] = invalid_indi_count\n",
        "\n",
        "        patient_indications = indi_clean.groupby('primaryid')['indi_pt_clean'].apply(\n",
        "            lambda x: list(set(x))\n",
        "        ).to_frame()\n",
        "        patient_indications.columns = ['indications']\n",
        "        patient_indications['num_indications'] = patient_indications['indications'].apply(len)\n",
        "\n",
        "        # ============= STEP 10: MERGE ALL DATA =============\n",
        "        log_step(f\"\\n10. Merging all datasets...\")\n",
        "\n",
        "        # Start with demographics\n",
        "        merged = demo_processed.copy()\n",
        "        initial_count = len(merged)\n",
        "\n",
        "        # Merge all components\n",
        "        merge_steps = [\n",
        "            (patient_suspect_drugs[['suspect_drugs', 'num_suspect_drugs', 'polypharmacy_category']], 'drugs'),\n",
        "            (patient_concom_drugs[['concomitant_drugs', 'num_concom_drugs']], 'concom_drugs'),\n",
        "            (patient_reactions[['all_reactions', 'num_reactions', 'has_serious_reaction', 'reaction_severity']], 'reactions'),\n",
        "            (patient_outcomes[['outcome_codes', 'is_serious_outcome', 'outcome_descriptions']], 'outcomes'),\n",
        "            (patient_indications[['indications', 'num_indications']], 'indications')\n",
        "        ]\n",
        "\n",
        "        for df_to_merge, name in merge_steps:\n",
        "            before_merge = len(merged)\n",
        "            merged = merged.merge(df_to_merge, left_on='primaryid', right_index=True, how='left')\n",
        "            after_merge = len(merged)\n",
        "\n",
        "            if before_merge != after_merge:\n",
        "                quality_report['issues_found'].append(f\"Row count changed during {name} merge: {before_merge} -> {after_merge}\")\n",
        "\n",
        "        # ============= STEP 11: QUALITY FILTERING =============\n",
        "        log_step(f\"\\n11. Quality filtering...\")\n",
        "\n",
        "        # Must have drugs and reactions for meaningful analysis\n",
        "        before_filter = len(merged)\n",
        "        has_drugs = merged['suspect_drugs'].notna()\n",
        "        has_reactions = merged['all_reactions'].notna()\n",
        "        valid_cases = has_drugs & has_reactions\n",
        "\n",
        "        merged = merged[valid_cases].copy()\n",
        "        filtered_count = before_filter - len(merged)\n",
        "\n",
        "        if filtered_count > 0:\n",
        "            log_step(f\"   Removed {filtered_count:,} incomplete cases\")\n",
        "            quality_report['data_quality_metrics']['incomplete_cases_removed'] = filtered_count\n",
        "\n",
        "        # ============= STEP 11.5: MISSING VALUE REPORT =============\n",
        "        if verbose:\n",
        "            log_step(f\"\\n11.5. Missing Value Analysis...\")\n",
        "\n",
        "            # Calculate missing values for each column\n",
        "            missing_report = {}\n",
        "            total_rows = len(merged)\n",
        "\n",
        "            print(f\"\\n{'='*60}\")\n",
        "            print(f\"MISSING VALUES REPORT FOR {quarter_name}\")\n",
        "            print(f\"{'='*60}\")\n",
        "            print(f\"Total cases: {total_rows:,}\")\n",
        "            print(f\"\\nColumns with missing values:\")\n",
        "            print(\"-\" * 40)\n",
        "\n",
        "            has_missing = False\n",
        "            for col in merged.columns:\n",
        "                missing_count = merged[col].isna().sum()\n",
        "                missing_pct = (missing_count / total_rows) * 100\n",
        "\n",
        "                missing_report[col] = {\n",
        "                    'missing_count': missing_count,\n",
        "                    'missing_pct': missing_pct\n",
        "                }\n",
        "\n",
        "                # Only show columns that have missing values\n",
        "                if missing_count > 0:\n",
        "                    has_missing = True\n",
        "                    print(f\"  {col:30s}: {missing_count:8,} ({missing_pct:5.1f}%)\")\n",
        "\n",
        "            if not has_missing:\n",
        "                print(\"No missing values in any column!\")\n",
        "\n",
        "            # Add to quality report\n",
        "            quality_report['data_quality_metrics']['missing_values'] = missing_report\n",
        "\n",
        "            # Show summary of completeness\n",
        "            print(f\"\\n{'='*60}\")\n",
        "            print(\"DATA COMPLETENESS SUMMARY:\")\n",
        "            print(\"-\" * 40)\n",
        "\n",
        "            # Categorize columns by completeness\n",
        "            complete_cols = []\n",
        "            partial_cols = []\n",
        "            sparse_cols = []\n",
        "\n",
        "            for col, stats in missing_report.items():\n",
        "                if stats['missing_pct'] == 0:\n",
        "                    complete_cols.append(col)\n",
        "                elif stats['missing_pct'] < 30:\n",
        "                    partial_cols.append(f\"{col} ({100-stats['missing_pct']:.1f}% complete)\")\n",
        "                else:\n",
        "                    sparse_cols.append(f\"{col} ({100-stats['missing_pct']:.1f}% complete)\")\n",
        "\n",
        "            print(f\"Fully Complete Columns ({len(complete_cols)}):\")\n",
        "            if complete_cols:\n",
        "                for col in complete_cols[:5]:  # Show first 5\n",
        "                    print(f\" {col}\")\n",
        "                if len(complete_cols) > 5:\n",
        "                    print(f\"  ... and {len(complete_cols)-5} more\")\n",
        "\n",
        "            if partial_cols:\n",
        "                print(f\"\\nPartially Complete Columns (>70% complete):\")\n",
        "                for col in partial_cols:\n",
        "                    print(f\" {col}\")\n",
        "\n",
        "            if sparse_cols:\n",
        "                print(f\"\\nSparse Columns (<70% complete):\")\n",
        "                for col in sparse_cols:\n",
        "                    print(f\" {col}\")\n",
        "\n",
        "            print(f\"{'='*60}\\n\")\n",
        "\n",
        "        # ============= STEP 12: CALCULATE FINAL METRICS =============\n",
        "        final_metrics = {\n",
        "            'total_cases': len(merged),\n",
        "            'cases_with_serious_reactions': merged['has_serious_reaction'].sum(),\n",
        "            'cases_with_serious_outcomes': merged['is_serious_outcome'].fillna(False).sum(),\n",
        "            'elderly_patients': merged['is_elderly'].sum(),\n",
        "            'pediatric_patients': merged['is_pediatric'].sum(),\n",
        "            'polypharmacy_cases': (merged['num_suspect_drugs'] >= 5).sum(),\n",
        "            'average_drugs_per_patient': merged['num_suspect_drugs'].mean(),\n",
        "            'average_reactions_per_patient': merged['num_reactions'].mean(),\n",
        "            'missing_age_pct': (merged['age_years'].isna().sum() / len(merged)) * 100,\n",
        "            'missing_country_pct': (merged['occr_country'].isna().sum() / len(merged)) * 100\n",
        "        }\n",
        "\n",
        "        quality_report['data_quality_metrics']['final_metrics'] = final_metrics\n",
        "\n",
        "        log_step(f\"\\n✓ {quarter_name} processed successfully!\")\n",
        "        log_step(f\"  Final shape: {merged.shape[0]:,} cases, {merged.shape[1]} features\")\n",
        "\n",
        "        # ============= STEP 13: SAVE PROCESSED DATA =============\n",
        "        log_step(f\"\\n12. Saving processed data...\")\n",
        "\n",
        "        # Create output directory if it doesn't exist\n",
        "        os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "        # Save processed data\n",
        "        pickle_path = f'{output_path}processed_{quarter_name}.pkl'\n",
        "        merged.to_pickle(pickle_path)\n",
        "        log_step(f\"   Saved to: {pickle_path}\")\n",
        "\n",
        "        # Save quality report\n",
        "        report_path = f'{output_path}quality_report_{quarter_name}.json'\n",
        "        with open(report_path, 'w') as f:\n",
        "            json.dump(quality_report, f, indent=2, default=str)\n",
        "        log_step(f\"   Quality report saved to: {report_path}\")\n",
        "\n",
        "        # ============= STEP 14: CLEANUP =============\n",
        "        log_step(f\"\\n13. Cleaning up temporary files...\")\n",
        "        import shutil\n",
        "        if os.path.exists(extract_path):\n",
        "            shutil.rmtree(extract_path)\n",
        "            log_step(f\"   Removed temporary extraction folder\")\n",
        "\n",
        "        return merged, quality_report\n",
        "\n",
        "    except Exception as e:\n",
        "        quality_report['error'] = str(e)\n",
        "        quality_report['status'] = 'FAILED'\n",
        "\n",
        "        # Save error report\n",
        "        error_report_path = f'{output_path}error_report_{quarter_name}.json'\n",
        "        with open(error_report_path, 'w') as f:\n",
        "            json.dump(quality_report, f, indent=2, default=str)\n",
        "\n",
        "        log_step(f\"\\nError processing {quarter_name}: {str(e)}\")\n",
        "        raise"
      ],
      "metadata": {
        "id": "r0Gcso577yBf"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Process all quarters"
      ],
      "metadata": {
        "id": "-OExgXmSBo0s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Process all quarters\n",
        "\n",
        "dataset_path = '/content/drive/MyDrive/Dataset/'\n",
        "output_path = '/content/drive/MyDrive/Dataset/processed_quarters/'\n",
        "os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "# Define quarters to process\n",
        "quarters_to_process = [\n",
        "    ('2024Q2', f'{dataset_path}faers_ascii_2024q2.zip'),\n",
        "    ('2024Q3', f'{dataset_path}faers_ascii_2024q3.zip'),\n",
        "    ('2024Q4', f'{dataset_path}faers_ascii_2024Q4.zip')  # Note: Q4 might be uppercase\n",
        "]\n",
        "\n",
        "# Store all processed data and reports\n",
        "all_processed_data = {}\n",
        "all_quality_reports = {}\n",
        "\n",
        "for quarter_name, zip_path in quarters_to_process:\n",
        "    try:\n",
        "        if os.path.exists(zip_path):\n",
        "            print(f\"\\n{'='*60}\")\n",
        "            print(f\"Processing {quarter_name}...\")\n",
        "            print(f\"{'='*60}\")\n",
        "\n",
        "            processed_data, quality_report = process_quarter(\n",
        "                quarter_name=quarter_name,\n",
        "                zip_path=zip_path,\n",
        "                output_path=output_path,\n",
        "                verbose=True\n",
        "            )\n",
        "\n",
        "            all_processed_data[quarter_name] = processed_data\n",
        "            all_quality_reports[quarter_name] = quality_report\n",
        "\n",
        "            print(f\"{quarter_name} completed successfully!\")\n",
        "            print(f\"   Cases: {len(processed_data):,}\")\n",
        "            print(f\"   Features: {processed_data.shape[1]}\")\n",
        "\n",
        "        else:\n",
        "            print(f\"Warning: {zip_path} not found, skipping {quarter_name}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to process {quarter_name}: {str(e)}\")\n",
        "        continue"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3BDu0tABNW3",
        "outputId": "f7ccbb5d-3b6f-426e-9b94-3bc8802a9041"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Processing 2024Q2...\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "PROCESSING 2024Q2\n",
            "============================================================\n",
            "1. Extracting /content/drive/MyDrive/Dataset/faers_ascii_2024q2.zip...\n",
            "   ASCII files found in: /content/2024Q2/ASCII\n",
            "\n",
            "2. Loading data files...\n",
            "   DEMO: 397,119 records\n",
            "   DRUG: 1,888,937 records\n",
            "   REAC: 1,445,044 records\n",
            "   OUTC: 291,572 records\n",
            "   INDI: 1,187,626 records\n",
            "\n",
            "3. Running data quality checks...\n",
            "\n",
            "4. Handling duplicates...\n",
            "   Removed 1249 duplicate drug records\n",
            "   Removed 21798 duplicate reaction records\n",
            "\n",
            "5. Processing demographics...\n",
            "\n",
            "6. Processing drugs...\n",
            "\n",
            "7. Processing reactions...\n",
            "\n",
            "8. Processing outcomes...\n",
            "\n",
            "9. Processing indications...\n",
            "\n",
            "10. Merging all datasets...\n",
            "\n",
            "11. Quality filtering...\n",
            "   Removed 563 incomplete cases\n",
            "\n",
            "11.5. Missing Value Analysis...\n",
            "\n",
            "============================================================\n",
            "MISSING VALUES REPORT FOR 2024Q2\n",
            "============================================================\n",
            "Total cases: 396,556\n",
            "\n",
            "Columns with missing values:\n",
            "----------------------------------------\n",
            "  age_years                     :  161,045 ( 40.6%)\n",
            "  age_group                     :  161,047 ( 40.6%)\n",
            "  occr_country                  :   38,260 (  9.6%)\n",
            "  concomitant_drugs             :  288,213 ( 72.7%)\n",
            "  num_concom_drugs              :  288,213 ( 72.7%)\n",
            "  outcome_codes                 :  176,636 ( 44.5%)\n",
            "  is_serious_outcome            :  176,636 ( 44.5%)\n",
            "  outcome_descriptions          :  176,636 ( 44.5%)\n",
            "  indications                   :  108,425 ( 27.3%)\n",
            "  num_indications               :  108,425 ( 27.3%)\n",
            "\n",
            "============================================================\n",
            "DATA COMPLETENESS SUMMARY:\n",
            "----------------------------------------\n",
            "Fully Complete Columns (11):\n",
            " primaryid\n",
            " sex_clean\n",
            " is_elderly\n",
            " is_pediatric\n",
            " suspect_drugs\n",
            "  ... and 6 more\n",
            "\n",
            "Partially Complete Columns (>70% complete):\n",
            " occr_country (90.4% complete)\n",
            " indications (72.7% complete)\n",
            " num_indications (72.7% complete)\n",
            "\n",
            "Sparse Columns (<70% complete):\n",
            " age_years (59.4% complete)\n",
            " age_group (59.4% complete)\n",
            " concomitant_drugs (27.3% complete)\n",
            " num_concom_drugs (27.3% complete)\n",
            " outcome_codes (55.5% complete)\n",
            " is_serious_outcome (55.5% complete)\n",
            " outcome_descriptions (55.5% complete)\n",
            "============================================================\n",
            "\n",
            "\n",
            "✓ 2024Q2 processed successfully!\n",
            "  Final shape: 396,556 cases, 21 features\n",
            "\n",
            "12. Saving processed data...\n",
            "   Saved to: /content/drive/MyDrive/Dataset/processed_quarters/processed_2024Q2.pkl\n",
            "   Quality report saved to: /content/drive/MyDrive/Dataset/processed_quarters/quality_report_2024Q2.json\n",
            "\n",
            "13. Cleaning up temporary files...\n",
            "   Removed temporary extraction folder\n",
            "2024Q2 completed successfully!\n",
            "   Cases: 396,556\n",
            "   Features: 21\n",
            "\n",
            "============================================================\n",
            "Processing 2024Q3...\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "PROCESSING 2024Q3\n",
            "============================================================\n",
            "1. Extracting /content/drive/MyDrive/Dataset/faers_ascii_2024q3.zip...\n",
            "   ASCII files found in: /content/2024Q3/ASCII\n",
            "\n",
            "2. Loading data files...\n",
            "   DEMO: 405,513 records\n",
            "   DRUG: 1,907,293 records\n",
            "   REAC: 1,431,718 records\n",
            "   OUTC: 288,275 records\n",
            "   INDI: 1,177,133 records\n",
            "\n",
            "3. Running data quality checks...\n",
            "\n",
            "4. Handling duplicates...\n",
            "   Removed 3946 duplicate drug records\n",
            "   Removed 18898 duplicate reaction records\n",
            "\n",
            "5. Processing demographics...\n",
            "\n",
            "6. Processing drugs...\n",
            "\n",
            "7. Processing reactions...\n",
            "\n",
            "8. Processing outcomes...\n",
            "\n",
            "9. Processing indications...\n",
            "\n",
            "10. Merging all datasets...\n",
            "\n",
            "11. Quality filtering...\n",
            "   Removed 345 incomplete cases\n",
            "\n",
            "11.5. Missing Value Analysis...\n",
            "\n",
            "============================================================\n",
            "MISSING VALUES REPORT FOR 2024Q3\n",
            "============================================================\n",
            "Total cases: 405,168\n",
            "\n",
            "Columns with missing values:\n",
            "----------------------------------------\n",
            "  age_years                     :  165,859 ( 40.9%)\n",
            "  age_group                     :  165,864 ( 40.9%)\n",
            "  occr_country                  :   29,915 (  7.4%)\n",
            "  concomitant_drugs             :  298,400 ( 73.6%)\n",
            "  num_concom_drugs              :  298,400 ( 73.6%)\n",
            "  outcome_codes                 :  187,546 ( 46.3%)\n",
            "  is_serious_outcome            :  187,546 ( 46.3%)\n",
            "  outcome_descriptions          :  187,546 ( 46.3%)\n",
            "  indications                   :  108,831 ( 26.9%)\n",
            "  num_indications               :  108,831 ( 26.9%)\n",
            "\n",
            "============================================================\n",
            "DATA COMPLETENESS SUMMARY:\n",
            "----------------------------------------\n",
            "Fully Complete Columns (11):\n",
            " primaryid\n",
            " sex_clean\n",
            " is_elderly\n",
            " is_pediatric\n",
            " suspect_drugs\n",
            "  ... and 6 more\n",
            "\n",
            "Partially Complete Columns (>70% complete):\n",
            " occr_country (92.6% complete)\n",
            " indications (73.1% complete)\n",
            " num_indications (73.1% complete)\n",
            "\n",
            "Sparse Columns (<70% complete):\n",
            " age_years (59.1% complete)\n",
            " age_group (59.1% complete)\n",
            " concomitant_drugs (26.4% complete)\n",
            " num_concom_drugs (26.4% complete)\n",
            " outcome_codes (53.7% complete)\n",
            " is_serious_outcome (53.7% complete)\n",
            " outcome_descriptions (53.7% complete)\n",
            "============================================================\n",
            "\n",
            "\n",
            "✓ 2024Q3 processed successfully!\n",
            "  Final shape: 405,168 cases, 21 features\n",
            "\n",
            "12. Saving processed data...\n",
            "   Saved to: /content/drive/MyDrive/Dataset/processed_quarters/processed_2024Q3.pkl\n",
            "   Quality report saved to: /content/drive/MyDrive/Dataset/processed_quarters/quality_report_2024Q3.json\n",
            "\n",
            "13. Cleaning up temporary files...\n",
            "   Removed temporary extraction folder\n",
            "2024Q3 completed successfully!\n",
            "   Cases: 405,168\n",
            "   Features: 21\n",
            "\n",
            "============================================================\n",
            "Processing 2024Q4...\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "PROCESSING 2024Q4\n",
            "============================================================\n",
            "1. Extracting /content/drive/MyDrive/Dataset/faers_ascii_2024Q4.zip...\n",
            "   ASCII files found in: /content/2024Q4/ASCII\n",
            "\n",
            "2. Loading data files...\n",
            "   DEMO: 410,849 records\n",
            "   DRUG: 2,030,938 records\n",
            "   REAC: 1,472,750 records\n",
            "   OUTC: 308,960 records\n",
            "   INDI: 1,219,759 records\n",
            "\n",
            "3. Running data quality checks...\n",
            "\n",
            "4. Handling duplicates...\n",
            "   Removed 36155 duplicate drug records\n",
            "   Removed 20252 duplicate reaction records\n",
            "\n",
            "5. Processing demographics...\n",
            "\n",
            "6. Processing drugs...\n",
            "\n",
            "7. Processing reactions...\n",
            "\n",
            "8. Processing outcomes...\n",
            "\n",
            "9. Processing indications...\n",
            "\n",
            "10. Merging all datasets...\n",
            "\n",
            "11. Quality filtering...\n",
            "   Removed 487 incomplete cases\n",
            "\n",
            "11.5. Missing Value Analysis...\n",
            "\n",
            "============================================================\n",
            "MISSING VALUES REPORT FOR 2024Q4\n",
            "============================================================\n",
            "Total cases: 410,362\n",
            "\n",
            "Columns with missing values:\n",
            "----------------------------------------\n",
            "  age_years                     :  160,848 ( 39.2%)\n",
            "  age_group                     :  160,850 ( 39.2%)\n",
            "  occr_country                  :   15,779 (  3.8%)\n",
            "  concomitant_drugs             :  299,114 ( 72.9%)\n",
            "  num_concom_drugs              :  299,114 ( 72.9%)\n",
            "  outcome_codes                 :  182,511 ( 44.5%)\n",
            "  is_serious_outcome            :  182,511 ( 44.5%)\n",
            "  outcome_descriptions          :  182,511 ( 44.5%)\n",
            "  indications                   :   99,608 ( 24.3%)\n",
            "  num_indications               :   99,608 ( 24.3%)\n",
            "\n",
            "============================================================\n",
            "DATA COMPLETENESS SUMMARY:\n",
            "----------------------------------------\n",
            "Fully Complete Columns (11):\n",
            " primaryid\n",
            " sex_clean\n",
            " is_elderly\n",
            " is_pediatric\n",
            " suspect_drugs\n",
            "  ... and 6 more\n",
            "\n",
            "Partially Complete Columns (>70% complete):\n",
            " occr_country (96.2% complete)\n",
            " indications (75.7% complete)\n",
            " num_indications (75.7% complete)\n",
            "\n",
            "Sparse Columns (<70% complete):\n",
            " age_years (60.8% complete)\n",
            " age_group (60.8% complete)\n",
            " concomitant_drugs (27.1% complete)\n",
            " num_concom_drugs (27.1% complete)\n",
            " outcome_codes (55.5% complete)\n",
            " is_serious_outcome (55.5% complete)\n",
            " outcome_descriptions (55.5% complete)\n",
            "============================================================\n",
            "\n",
            "\n",
            "✓ 2024Q4 processed successfully!\n",
            "  Final shape: 410,362 cases, 21 features\n",
            "\n",
            "12. Saving processed data...\n",
            "   Saved to: /content/drive/MyDrive/Dataset/processed_quarters/processed_2024Q4.pkl\n",
            "   Quality report saved to: /content/drive/MyDrive/Dataset/processed_quarters/quality_report_2024Q4.json\n",
            "\n",
            "13. Cleaning up temporary files...\n",
            "   Removed temporary extraction folder\n",
            "2024Q4 completed successfully!\n",
            "   Cases: 410,362\n",
            "   Features: 21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Validation & Quality Assurance"
      ],
      "metadata": {
        "id": "JyUCfN3zEV3u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_processed_quarters(output_path):\n",
        "    \"\"\"\n",
        "    Validate that all quarters were processed consistently\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"VALIDATING PROCESSED QUARTERS\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Load all processed quarters\n",
        "    processed_files = glob.glob(f'{output_path}processed_*.pkl')\n",
        "\n",
        "    if not processed_files:\n",
        "        print(\"No processed files found!\")\n",
        "        return\n",
        "\n",
        "    quarters_data = {}\n",
        "    for file_path in processed_files:\n",
        "        quarter_name = os.path.basename(file_path).replace('processed_', '').replace('.pkl', '')\n",
        "        quarters_data[quarter_name] = pd.read_pickle(file_path)\n",
        "\n",
        "    print(f\"\\nFound {len(quarters_data)} processed quarters:\")\n",
        "\n",
        "    # Check consistency\n",
        "    validation_results = {}\n",
        "\n",
        "    for quarter_name, data in sorted(quarters_data.items()):\n",
        "        print(f\"\\n{quarter_name}:\")\n",
        "        print(f\"  Shape: {data.shape}\")\n",
        "        print(f\"  Columns: {list(data.columns)}\")\n",
        "\n",
        "        validation_results[quarter_name] = {\n",
        "            'shape': data.shape,\n",
        "            'columns': list(data.columns),\n",
        "            'missing_values': data.isnull().sum().to_dict(),\n",
        "            'serious_reaction_rate': (data['has_serious_reaction'].sum() / len(data)) * 100,\n",
        "            'elderly_rate': (data['is_elderly'].sum() / len(data)) * 100,\n",
        "            'avg_drugs': data['num_suspect_drugs'].mean(),\n",
        "            'avg_reactions': data['num_reactions'].mean()\n",
        "        }\n",
        "\n",
        "    # Check if all quarters have same columns\n",
        "    all_columns = [set(v['columns']) for v in validation_results.values()]\n",
        "    if len(set(map(tuple, all_columns))) == 1:\n",
        "        print(\"\\nAll quarters have consistent columns\")\n",
        "    else:\n",
        "        print(\"\\nWarning: Quarters have different columns!\")\n",
        "\n",
        "    # Compare key metrics across quarters\n",
        "    print(\"\\nKey Metrics Comparison:\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    metrics_df = pd.DataFrame({\n",
        "        quarter: {\n",
        "            'Cases': results['shape'][0],\n",
        "            'Serious Reactions %': f\"{results['serious_reaction_rate']:.1f}\",\n",
        "            'Elderly %': f\"{results['elderly_rate']:.1f}\",\n",
        "            'Avg Drugs': f\"{results['avg_drugs']:.2f}\",\n",
        "            'Avg Reactions': f\"{results['avg_reactions']:.2f}\"\n",
        "        }\n",
        "        for quarter, results in validation_results.items()\n",
        "    }).T\n",
        "\n",
        "    print(metrics_df)\n",
        "\n",
        "    return validation_results\n",
        "\n",
        "# Run validation\n",
        "validation_results = validate_processed_quarters(output_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulP3ISjaCKlR",
        "outputId": "3c36dcd8-ef0f-423f-f100-213aadb62220"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "VALIDATING PROCESSED QUARTERS\n",
            "============================================================\n",
            "\n",
            "Found 4 processed quarters:\n",
            "\n",
            "2024Q1:\n",
            "  Shape: (405814, 21)\n",
            "  Columns: ['primaryid', 'age_years', 'age_group', 'sex_clean', 'occr_country', 'is_elderly', 'is_pediatric', 'suspect_drugs', 'num_suspect_drugs', 'polypharmacy_category', 'concomitant_drugs', 'num_concom_drugs', 'all_reactions', 'num_reactions', 'has_serious_reaction', 'reaction_severity', 'outcome_codes', 'is_serious_outcome', 'outcome_descriptions', 'indications', 'num_indications']\n",
            "\n",
            "2024Q2:\n",
            "  Shape: (396556, 21)\n",
            "  Columns: ['primaryid', 'age_years', 'age_group', 'sex_clean', 'occr_country', 'is_elderly', 'is_pediatric', 'suspect_drugs', 'num_suspect_drugs', 'polypharmacy_category', 'concomitant_drugs', 'num_concom_drugs', 'all_reactions', 'num_reactions', 'has_serious_reaction', 'reaction_severity', 'outcome_codes', 'is_serious_outcome', 'outcome_descriptions', 'indications', 'num_indications']\n",
            "\n",
            "2024Q3:\n",
            "  Shape: (405168, 21)\n",
            "  Columns: ['primaryid', 'age_years', 'age_group', 'sex_clean', 'occr_country', 'is_elderly', 'is_pediatric', 'suspect_drugs', 'num_suspect_drugs', 'polypharmacy_category', 'concomitant_drugs', 'num_concom_drugs', 'all_reactions', 'num_reactions', 'has_serious_reaction', 'reaction_severity', 'outcome_codes', 'is_serious_outcome', 'outcome_descriptions', 'indications', 'num_indications']\n",
            "\n",
            "2024Q4:\n",
            "  Shape: (410362, 21)\n",
            "  Columns: ['primaryid', 'age_years', 'age_group', 'sex_clean', 'occr_country', 'is_elderly', 'is_pediatric', 'suspect_drugs', 'num_suspect_drugs', 'polypharmacy_category', 'concomitant_drugs', 'num_concom_drugs', 'all_reactions', 'num_reactions', 'has_serious_reaction', 'reaction_severity', 'outcome_codes', 'is_serious_outcome', 'outcome_descriptions', 'indications', 'num_indications']\n",
            "\n",
            "All quarters have consistent columns\n",
            "\n",
            "Key Metrics Comparison:\n",
            "----------------------------------------\n",
            "         Cases Serious Reactions % Elderly % Avg Drugs Avg Reactions\n",
            "2024Q1  405814                12.0      24.3      1.66          3.49\n",
            "2024Q2  396556                 7.0      23.9      1.72          3.57\n",
            "2024Q3  405168                 6.6      23.2      1.69          3.47\n",
            "2024Q4  410362                 7.3      23.2      1.72          3.51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Now we are processing 2025 Dataset"
      ],
      "metadata": {
        "id": "Qx-IKF5fd9si"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Process 2025 quarters with CORRECT quarter names\n",
        "quarters_to_process = [\n",
        "    ('2025Q1', f'{dataset_path}faers_ascii_2025q1.zip'),  # Changed from 2024Q2 to 2025Q1\n",
        "    ('2025Q2', f'{dataset_path}faers_ascii_2025q2.zip'),  # Fixed: was '205q2' (missing '2')\n",
        "    ('2025Q3', f'{dataset_path}faers_ascii_2025q3.zip')   # Changed from 2024Q3 to 2025Q3\n",
        "]\n",
        "\n",
        "# Store all processed data and reports\n",
        "all_processed_data = {}\n",
        "all_quality_reports = {}\n",
        "\n",
        "for quarter_name, zip_path in quarters_to_process:\n",
        "    try:\n",
        "        if os.path.exists(zip_path):\n",
        "            print(f\"\\n{'='*60}\")\n",
        "            print(f\"Processing {quarter_name}...\")\n",
        "            print(f\"{'='*60}\")\n",
        "\n",
        "            processed_data, quality_report = process_quarter(\n",
        "                quarter_name=quarter_name,\n",
        "                zip_path=zip_path,\n",
        "                output_path=output_path,\n",
        "                verbose=True\n",
        "            )\n",
        "\n",
        "            all_processed_data[quarter_name] = processed_data\n",
        "            all_quality_reports[quarter_name] = quality_report\n",
        "\n",
        "            print(f\"{quarter_name} completed successfully!\")\n",
        "            print(f\"   Cases: {len(processed_data):,}\")\n",
        "            print(f\"   Features: {processed_data.shape[1]}\")\n",
        "\n",
        "        else:\n",
        "            print(f\"Warning: {zip_path} not found, skipping {quarter_name}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to process {quarter_name}: {str(e)}\")\n",
        "        continue"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPvHUe4LEl5h",
        "outputId": "0fe0dbb7-9ed7-48bf-ced5-8973f1c7f93e"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Processing 2025Q1...\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "PROCESSING 2025Q1\n",
            "============================================================\n",
            "1. Extracting /content/drive/MyDrive/Dataset/faers_ascii_2025q1.zip...\n",
            "   ASCII files found in: /content/2025Q1/ASCII\n",
            "\n",
            "2. Loading data files...\n",
            "   DEMO: 400,514 records\n",
            "   DRUG: 2,008,162 records\n",
            "   REAC: 1,432,926 records\n",
            "   OUTC: 304,027 records\n",
            "   INDI: 1,205,861 records\n",
            "\n",
            "3. Running data quality checks...\n",
            "\n",
            "4. Handling duplicates...\n",
            "   Removed 46753 duplicate drug records\n",
            "   Removed 18571 duplicate reaction records\n",
            "\n",
            "5. Processing demographics...\n",
            "\n",
            "6. Processing drugs...\n",
            "\n",
            "7. Processing reactions...\n",
            "\n",
            "8. Processing outcomes...\n",
            "\n",
            "9. Processing indications...\n",
            "\n",
            "10. Merging all datasets...\n",
            "\n",
            "11. Quality filtering...\n",
            "   Removed 627 incomplete cases\n",
            "\n",
            "11.5. Missing Value Analysis...\n",
            "\n",
            "============================================================\n",
            "MISSING VALUES REPORT FOR 2025Q1\n",
            "============================================================\n",
            "Total cases: 399,887\n",
            "\n",
            "Columns with missing values:\n",
            "----------------------------------------\n",
            "  age_years                     :  156,691 ( 39.2%)\n",
            "  age_group                     :  156,696 ( 39.2%)\n",
            "  occr_country                  :   16,126 (  4.0%)\n",
            "  concomitant_drugs             :  290,357 ( 72.6%)\n",
            "  num_concom_drugs              :  290,357 ( 72.6%)\n",
            "  outcome_codes                 :  175,194 ( 43.8%)\n",
            "  is_serious_outcome            :  175,194 ( 43.8%)\n",
            "  outcome_descriptions          :  175,194 ( 43.8%)\n",
            "  indications                   :  104,415 ( 26.1%)\n",
            "  num_indications               :  104,415 ( 26.1%)\n",
            "\n",
            "============================================================\n",
            "DATA COMPLETENESS SUMMARY:\n",
            "----------------------------------------\n",
            "Fully Complete Columns (11):\n",
            " primaryid\n",
            " sex_clean\n",
            " is_elderly\n",
            " is_pediatric\n",
            " suspect_drugs\n",
            "  ... and 6 more\n",
            "\n",
            "Partially Complete Columns (>70% complete):\n",
            " occr_country (96.0% complete)\n",
            " indications (73.9% complete)\n",
            " num_indications (73.9% complete)\n",
            "\n",
            "Sparse Columns (<70% complete):\n",
            " age_years (60.8% complete)\n",
            " age_group (60.8% complete)\n",
            " concomitant_drugs (27.4% complete)\n",
            " num_concom_drugs (27.4% complete)\n",
            " outcome_codes (56.2% complete)\n",
            " is_serious_outcome (56.2% complete)\n",
            " outcome_descriptions (56.2% complete)\n",
            "============================================================\n",
            "\n",
            "\n",
            "✓ 2025Q1 processed successfully!\n",
            "  Final shape: 399,887 cases, 21 features\n",
            "\n",
            "12. Saving processed data...\n",
            "   Saved to: /content/drive/MyDrive/Dataset/processed_quarters/processed_2025Q1.pkl\n",
            "   Quality report saved to: /content/drive/MyDrive/Dataset/processed_quarters/quality_report_2025Q1.json\n",
            "\n",
            "13. Cleaning up temporary files...\n",
            "   Removed temporary extraction folder\n",
            "2025Q1 completed successfully!\n",
            "   Cases: 399,887\n",
            "   Features: 21\n",
            "\n",
            "============================================================\n",
            "Processing 2025Q2...\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "PROCESSING 2025Q2\n",
            "============================================================\n",
            "1. Extracting /content/drive/MyDrive/Dataset/faers_ascii_2025q2.zip...\n",
            "   ASCII files found in: /content/2025Q2/ASCII\n",
            "\n",
            "2. Loading data files...\n",
            "   DEMO: 393,130 records\n",
            "   DRUG: 1,829,056 records\n",
            "   REAC: 1,340,666 records\n",
            "   OUTC: 295,583 records\n",
            "   INDI: 1,136,665 records\n",
            "\n",
            "3. Running data quality checks...\n",
            "\n",
            "4. Handling duplicates...\n",
            "   Removed 62667 duplicate drug records\n",
            "   Removed 17244 duplicate reaction records\n",
            "\n",
            "5. Processing demographics...\n",
            "\n",
            "6. Processing drugs...\n",
            "\n",
            "7. Processing reactions...\n",
            "\n",
            "8. Processing outcomes...\n",
            "\n",
            "9. Processing indications...\n",
            "\n",
            "10. Merging all datasets...\n",
            "\n",
            "11. Quality filtering...\n",
            "   Removed 787 incomplete cases\n",
            "\n",
            "11.5. Missing Value Analysis...\n",
            "\n",
            "============================================================\n",
            "MISSING VALUES REPORT FOR 2025Q2\n",
            "============================================================\n",
            "Total cases: 392,343\n",
            "\n",
            "Columns with missing values:\n",
            "----------------------------------------\n",
            "  age_years                     :  155,436 ( 39.6%)\n",
            "  age_group                     :  155,442 ( 39.6%)\n",
            "  occr_country                  :   17,483 (  4.5%)\n",
            "  concomitant_drugs             :  284,742 ( 72.6%)\n",
            "  num_concom_drugs              :  284,742 ( 72.6%)\n",
            "  outcome_codes                 :  170,059 ( 43.3%)\n",
            "  is_serious_outcome            :  170,059 ( 43.3%)\n",
            "  outcome_descriptions          :  170,059 ( 43.3%)\n",
            "  indications                   :   97,556 ( 24.9%)\n",
            "  num_indications               :   97,556 ( 24.9%)\n",
            "\n",
            "============================================================\n",
            "DATA COMPLETENESS SUMMARY:\n",
            "----------------------------------------\n",
            "Fully Complete Columns (11):\n",
            " primaryid\n",
            " sex_clean\n",
            " is_elderly\n",
            " is_pediatric\n",
            " suspect_drugs\n",
            "  ... and 6 more\n",
            "\n",
            "Partially Complete Columns (>70% complete):\n",
            " occr_country (95.5% complete)\n",
            " indications (75.1% complete)\n",
            " num_indications (75.1% complete)\n",
            "\n",
            "Sparse Columns (<70% complete):\n",
            " age_years (60.4% complete)\n",
            " age_group (60.4% complete)\n",
            " concomitant_drugs (27.4% complete)\n",
            " num_concom_drugs (27.4% complete)\n",
            " outcome_codes (56.7% complete)\n",
            " is_serious_outcome (56.7% complete)\n",
            " outcome_descriptions (56.7% complete)\n",
            "============================================================\n",
            "\n",
            "\n",
            "✓ 2025Q2 processed successfully!\n",
            "  Final shape: 392,343 cases, 21 features\n",
            "\n",
            "12. Saving processed data...\n",
            "   Saved to: /content/drive/MyDrive/Dataset/processed_quarters/processed_2025Q2.pkl\n",
            "   Quality report saved to: /content/drive/MyDrive/Dataset/processed_quarters/quality_report_2025Q2.json\n",
            "\n",
            "13. Cleaning up temporary files...\n",
            "   Removed temporary extraction folder\n",
            "2025Q2 completed successfully!\n",
            "   Cases: 392,343\n",
            "   Features: 21\n",
            "\n",
            "============================================================\n",
            "Processing 2025Q3...\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "PROCESSING 2025Q3\n",
            "============================================================\n",
            "1. Extracting /content/drive/MyDrive/Dataset/faers_ascii_2025q3.zip...\n",
            "   ASCII files found in: /content/2025Q3/ASCII\n",
            "\n",
            "2. Loading data files...\n",
            "   DEMO: 438,512 records\n",
            "   DRUG: 2,148,451 records\n",
            "   REAC: 1,535,133 records\n",
            "   OUTC: 343,251 records\n",
            "   INDI: 1,310,274 records\n",
            "\n",
            "3. Running data quality checks...\n",
            "\n",
            "4. Handling duplicates...\n",
            "   Removed 80855 duplicate drug records\n",
            "   Removed 18045 duplicate reaction records\n",
            "\n",
            "5. Processing demographics...\n",
            "\n",
            "6. Processing drugs...\n",
            "\n",
            "7. Processing reactions...\n",
            "\n",
            "8. Processing outcomes...\n",
            "\n",
            "9. Processing indications...\n",
            "\n",
            "10. Merging all datasets...\n",
            "\n",
            "11. Quality filtering...\n",
            "   Removed 431 incomplete cases\n",
            "\n",
            "11.5. Missing Value Analysis...\n",
            "\n",
            "============================================================\n",
            "MISSING VALUES REPORT FOR 2025Q3\n",
            "============================================================\n",
            "Total cases: 438,081\n",
            "\n",
            "Columns with missing values:\n",
            "----------------------------------------\n",
            "  age_years                     :  180,845 ( 41.3%)\n",
            "  age_group                     :  180,860 ( 41.3%)\n",
            "  occr_country                  :   16,663 (  3.8%)\n",
            "  concomitant_drugs             :  318,038 ( 72.6%)\n",
            "  num_concom_drugs              :  318,038 ( 72.6%)\n",
            "  outcome_codes                 :  183,701 ( 41.9%)\n",
            "  is_serious_outcome            :  183,701 ( 41.9%)\n",
            "  outcome_descriptions          :  183,701 ( 41.9%)\n",
            "  indications                   :  119,021 ( 27.2%)\n",
            "  num_indications               :  119,021 ( 27.2%)\n",
            "\n",
            "============================================================\n",
            "DATA COMPLETENESS SUMMARY:\n",
            "----------------------------------------\n",
            "Fully Complete Columns (11):\n",
            " primaryid\n",
            " sex_clean\n",
            " is_elderly\n",
            " is_pediatric\n",
            " suspect_drugs\n",
            "  ... and 6 more\n",
            "\n",
            "Partially Complete Columns (>70% complete):\n",
            " occr_country (96.2% complete)\n",
            " indications (72.8% complete)\n",
            " num_indications (72.8% complete)\n",
            "\n",
            "Sparse Columns (<70% complete):\n",
            " age_years (58.7% complete)\n",
            " age_group (58.7% complete)\n",
            " concomitant_drugs (27.4% complete)\n",
            " num_concom_drugs (27.4% complete)\n",
            " outcome_codes (58.1% complete)\n",
            " is_serious_outcome (58.1% complete)\n",
            " outcome_descriptions (58.1% complete)\n",
            "============================================================\n",
            "\n",
            "\n",
            "✓ 2025Q3 processed successfully!\n",
            "  Final shape: 438,081 cases, 21 features\n",
            "\n",
            "12. Saving processed data...\n",
            "   Saved to: /content/drive/MyDrive/Dataset/processed_quarters/processed_2025Q3.pkl\n",
            "   Quality report saved to: /content/drive/MyDrive/Dataset/processed_quarters/quality_report_2025Q3.json\n",
            "\n",
            "13. Cleaning up temporary files...\n",
            "   Removed temporary extraction folder\n",
            "2025Q3 completed successfully!\n",
            "   Cases: 438,081\n",
            "   Features: 21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Validation & Quality Assurance"
      ],
      "metadata": {
        "id": "ZoU2ntiKfog3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_processed_quarters(output_path):\n",
        "    \"\"\"\n",
        "    Validate that all quarters were processed consistently\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"VALIDATING PROCESSED QUARTERS\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Load all processed quarters\n",
        "    processed_files = glob.glob(f'{output_path}processed_*.pkl')\n",
        "\n",
        "    if not processed_files:\n",
        "        print(\"No processed files found!\")\n",
        "        return\n",
        "\n",
        "    quarters_data = {}\n",
        "    for file_path in processed_files:\n",
        "        quarter_name = os.path.basename(file_path).replace('processed_', '').replace('.pkl', '')\n",
        "        quarters_data[quarter_name] = pd.read_pickle(file_path)\n",
        "\n",
        "    print(f\"\\nFound {len(quarters_data)} processed quarters:\")\n",
        "\n",
        "    # Check consistency\n",
        "    validation_results = {}\n",
        "\n",
        "    for quarter_name, data in sorted(quarters_data.items()):\n",
        "        print(f\"\\n{quarter_name}:\")\n",
        "        print(f\"  Shape: {data.shape}\")\n",
        "        print(f\"  Columns: {list(data.columns)}\")\n",
        "\n",
        "        validation_results[quarter_name] = {\n",
        "            'shape': data.shape,\n",
        "            'columns': list(data.columns),\n",
        "            'missing_values': data.isnull().sum().to_dict(),\n",
        "            'serious_reaction_rate': (data['has_serious_reaction'].sum() / len(data)) * 100,\n",
        "            'elderly_rate': (data['is_elderly'].sum() / len(data)) * 100,\n",
        "            'avg_drugs': data['num_suspect_drugs'].mean(),\n",
        "            'avg_reactions': data['num_reactions'].mean()\n",
        "        }\n",
        "\n",
        "    # Check if all quarters have same columns\n",
        "    all_columns = [set(v['columns']) for v in validation_results.values()]\n",
        "    if len(set(map(tuple, all_columns))) == 1:\n",
        "        print(\"\\nAll quarters have consistent columns\")\n",
        "    else:\n",
        "        print(\"\\nWarning: Quarters have different columns!\")\n",
        "\n",
        "    # Compare key metrics across quarters\n",
        "    print(\"\\nKey Metrics Comparison:\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    metrics_df = pd.DataFrame({\n",
        "        quarter: {\n",
        "            'Cases': results['shape'][0],\n",
        "            'Serious Reactions %': f\"{results['serious_reaction_rate']:.1f}\",\n",
        "            'Elderly %': f\"{results['elderly_rate']:.1f}\",\n",
        "            'Avg Drugs': f\"{results['avg_drugs']:.2f}\",\n",
        "            'Avg Reactions': f\"{results['avg_reactions']:.2f}\"\n",
        "        }\n",
        "        for quarter, results in validation_results.items()\n",
        "    }).T\n",
        "\n",
        "    print(metrics_df)\n",
        "\n",
        "    return validation_results\n",
        "\n",
        "# Run validation\n",
        "validation_results = validate_processed_quarters(output_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFnvU11DePIj",
        "outputId": "c25028a5-fed7-46a8-bbad-ca3adff8d492"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "VALIDATING PROCESSED QUARTERS\n",
            "============================================================\n",
            "\n",
            "Found 7 processed quarters:\n",
            "\n",
            "2024Q1:\n",
            "  Shape: (405814, 21)\n",
            "  Columns: ['primaryid', 'age_years', 'age_group', 'sex_clean', 'occr_country', 'is_elderly', 'is_pediatric', 'suspect_drugs', 'num_suspect_drugs', 'polypharmacy_category', 'concomitant_drugs', 'num_concom_drugs', 'all_reactions', 'num_reactions', 'has_serious_reaction', 'reaction_severity', 'outcome_codes', 'is_serious_outcome', 'outcome_descriptions', 'indications', 'num_indications']\n",
            "\n",
            "2024Q2:\n",
            "  Shape: (396556, 21)\n",
            "  Columns: ['primaryid', 'age_years', 'age_group', 'sex_clean', 'occr_country', 'is_elderly', 'is_pediatric', 'suspect_drugs', 'num_suspect_drugs', 'polypharmacy_category', 'concomitant_drugs', 'num_concom_drugs', 'all_reactions', 'num_reactions', 'has_serious_reaction', 'reaction_severity', 'outcome_codes', 'is_serious_outcome', 'outcome_descriptions', 'indications', 'num_indications']\n",
            "\n",
            "2024Q3:\n",
            "  Shape: (405168, 21)\n",
            "  Columns: ['primaryid', 'age_years', 'age_group', 'sex_clean', 'occr_country', 'is_elderly', 'is_pediatric', 'suspect_drugs', 'num_suspect_drugs', 'polypharmacy_category', 'concomitant_drugs', 'num_concom_drugs', 'all_reactions', 'num_reactions', 'has_serious_reaction', 'reaction_severity', 'outcome_codes', 'is_serious_outcome', 'outcome_descriptions', 'indications', 'num_indications']\n",
            "\n",
            "2024Q4:\n",
            "  Shape: (410362, 21)\n",
            "  Columns: ['primaryid', 'age_years', 'age_group', 'sex_clean', 'occr_country', 'is_elderly', 'is_pediatric', 'suspect_drugs', 'num_suspect_drugs', 'polypharmacy_category', 'concomitant_drugs', 'num_concom_drugs', 'all_reactions', 'num_reactions', 'has_serious_reaction', 'reaction_severity', 'outcome_codes', 'is_serious_outcome', 'outcome_descriptions', 'indications', 'num_indications']\n",
            "\n",
            "2025Q1:\n",
            "  Shape: (399887, 21)\n",
            "  Columns: ['primaryid', 'age_years', 'age_group', 'sex_clean', 'occr_country', 'is_elderly', 'is_pediatric', 'suspect_drugs', 'num_suspect_drugs', 'polypharmacy_category', 'concomitant_drugs', 'num_concom_drugs', 'all_reactions', 'num_reactions', 'has_serious_reaction', 'reaction_severity', 'outcome_codes', 'is_serious_outcome', 'outcome_descriptions', 'indications', 'num_indications']\n",
            "\n",
            "2025Q2:\n",
            "  Shape: (392343, 21)\n",
            "  Columns: ['primaryid', 'age_years', 'age_group', 'sex_clean', 'occr_country', 'is_elderly', 'is_pediatric', 'suspect_drugs', 'num_suspect_drugs', 'polypharmacy_category', 'concomitant_drugs', 'num_concom_drugs', 'all_reactions', 'num_reactions', 'has_serious_reaction', 'reaction_severity', 'outcome_codes', 'is_serious_outcome', 'outcome_descriptions', 'indications', 'num_indications']\n",
            "\n",
            "2025Q3:\n",
            "  Shape: (438081, 21)\n",
            "  Columns: ['primaryid', 'age_years', 'age_group', 'sex_clean', 'occr_country', 'is_elderly', 'is_pediatric', 'suspect_drugs', 'num_suspect_drugs', 'polypharmacy_category', 'concomitant_drugs', 'num_concom_drugs', 'all_reactions', 'num_reactions', 'has_serious_reaction', 'reaction_severity', 'outcome_codes', 'is_serious_outcome', 'outcome_descriptions', 'indications', 'num_indications']\n",
            "\n",
            "All quarters have consistent columns\n",
            "\n",
            "Key Metrics Comparison:\n",
            "----------------------------------------\n",
            "         Cases Serious Reactions % Elderly % Avg Drugs Avg Reactions\n",
            "2024Q1  405814                12.0      24.3      1.66          3.49\n",
            "2024Q2  396556                 7.0      23.9      1.72          3.57\n",
            "2024Q3  405168                 6.6      23.2      1.69          3.47\n",
            "2024Q4  410362                 7.3      23.2      1.72          3.51\n",
            "2025Q1  399887                 7.5      23.6      1.72          3.52\n",
            "2025Q2  392343                 7.1      23.3      1.62          3.36\n",
            "2025Q3  438081                 8.0      23.4      1.70          3.46\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Merge all 7 files"
      ],
      "metadata": {
        "id": "IORAXYcMf827"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check what files we have\n",
        "processed_files = sorted(glob.glob(f'{output_path}processed_*.pkl'))\n",
        "\n",
        "print(\"Found processed files:\")\n",
        "print(\"-\" * 40)\n",
        "for file in processed_files:\n",
        "    quarter = file.split('processed_')[1].replace('.pkl', '')\n",
        "    data = pd.read_pickle(file)\n",
        "    print(f\"{quarter}: {data.shape[0]:,} cases, {data.shape[1]} columns\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmey6AxEfrZq",
        "outputId": "9e5f1ec3-c894-479b-ffad-92528b3e5b7b"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found processed files:\n",
            "----------------------------------------\n",
            "quarters/: 405,814 cases, 21 columns\n",
            "quarters/: 396,556 cases, 21 columns\n",
            "quarters/: 405,168 cases, 21 columns\n",
            "quarters/: 410,362 cases, 21 columns\n",
            "quarters/: 399,887 cases, 21 columns\n",
            "quarters/: 392,343 cases, 21 columns\n",
            "quarters/: 438,081 cases, 21 columns\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load all processed quarters\n",
        "\n",
        "# 3. Set the path to your processed quarters\n",
        "output_path = '/content/drive/MyDrive/Dataset/processed_quarters/'\n",
        "\n",
        "all_data = []\n",
        "quarters = ['2024Q1', '2024Q2', '2024Q3', '2024Q4', '2025Q1', '2025Q2', '2025Q3']\n",
        "\n",
        "for quarter in quarters:\n",
        "    file_path = f'{output_path}processed_{quarter}.pkl'\n",
        "    try:\n",
        "        print(f\"Loading {quarter}...\")\n",
        "        data = pd.read_pickle(file_path)\n",
        "        all_data.append(data)\n",
        "        print(f\"  Loaded {len(data):,} cases, {data.shape[1]} columns\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"  {quarter} not found, skipping\")\n",
        "        continue\n",
        "\n",
        "# Combine all quarters\n",
        "print(\"\\nCombining all loaded quarters...\")\n",
        "final_dataset = pd.concat(all_data, ignore_index=True)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"MERGED DATASET OVERVIEW\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Display basic info\n",
        "print(f\"Shape: {final_dataset.shape}\")\n",
        "print(f\"Total cases: {final_dataset.shape[0]:,}\")\n",
        "print(f\"Total features: {final_dataset.shape[1]}\")\n",
        "print(f\"Memory usage: {final_dataset.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
        "\n",
        "# Check for duplicates\n",
        "duplicate_primaryids = final_dataset['primaryid'].duplicated().sum()\n",
        "if duplicate_primaryids > 0:\n",
        "    print(f\"\\nFound {duplicate_primaryids:,} duplicate primaryids\")\n",
        "    final_dataset = final_dataset.drop_duplicates(subset=['primaryid'], keep='first')\n",
        "    print(f\"After removing duplicates: {final_dataset.shape[0]:,} cases\")\n",
        "\n",
        "# View first few rows\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FIRST 5 ROWS OF MERGED DATASET\")\n",
        "print(\"=\"*60)\n",
        "print(final_dataset.head())\n",
        "\n",
        "# View column names\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"COLUMNS IN FINAL DATASET\")\n",
        "print(\"=\"*60)\n",
        "print(list(final_dataset.columns))\n",
        "\n",
        "# Quick statistics\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"QUICK STATISTICS\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Unique patients: {final_dataset['primaryid'].nunique():,}\")\n",
        "print(f\"Elderly patients: {final_dataset['is_elderly'].sum():,}\")\n",
        "print(f\"Pediatric patients: {final_dataset['is_pediatric'].sum():,}\")\n",
        "print(f\"Cases with serious reactions: {final_dataset['has_serious_reaction'].sum():,}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrLed1Xjf_nG",
        "outputId": "d34fe11a-bf22-451f-a209-d195c298df61"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading 2024Q1...\n",
            "  Loaded 405,814 cases, 21 columns\n",
            "Loading 2024Q2...\n",
            "  Loaded 396,556 cases, 21 columns\n",
            "Loading 2024Q3...\n",
            "  Loaded 405,168 cases, 21 columns\n",
            "Loading 2024Q4...\n",
            "  Loaded 410,362 cases, 21 columns\n",
            "Loading 2025Q1...\n",
            "  Loaded 399,887 cases, 21 columns\n",
            "Loading 2025Q2...\n",
            "  Loaded 392,343 cases, 21 columns\n",
            "Loading 2025Q3...\n",
            "  Loaded 438,081 cases, 21 columns\n",
            "\n",
            "Combining all loaded quarters...\n",
            "\n",
            "============================================================\n",
            "MERGED DATASET OVERVIEW\n",
            "============================================================\n",
            "Shape: (2848211, 21)\n",
            "Total cases: 2,848,211\n",
            "Total features: 21\n",
            "Memory usage: 2062.18 MB\n",
            "\n",
            "Found 132 duplicate primaryids\n",
            "After removing duplicates: 2,848,079 cases\n",
            "\n",
            "============================================================\n",
            "FIRST 5 ROWS OF MERGED DATASET\n",
            "============================================================\n",
            "    primaryid  age_years   age_group sex_clean occr_country  is_elderly  \\\n",
            "0  1001678125       56.0  middle_age    Female           CA           0   \n",
            "1  1002872124       57.0  middle_age    Female           CA           0   \n",
            "2   100293663       32.0       adult      Male           AU           0   \n",
            "3  1005450710       68.0     elderly    Female           US           1   \n",
            "4  1005762118       57.0  middle_age      Male           CA           0   \n",
            "\n",
            "   is_pediatric                                      suspect_drugs  \\\n",
            "0             0               [SANDOSTATIN LAR DEPOT, SANDOSTATIN]   \n",
            "1             0     [SANDOSTATIN LAR DEPOT, AFINITOR, SANDOSTATIN]   \n",
            "2             0  [CYCLOSPORINE, BASILIXIMAB, MYCOPHENOLATE MOFE...   \n",
            "3             0                      [ENBREL, METHOTREXATE SODIUM]   \n",
            "4             0                                   [EXELON, XOLAIR]   \n",
            "\n",
            "   num_suspect_drugs polypharmacy_category  ... num_concom_drugs  \\\n",
            "0                2.0          dual_therapy  ...             11.0   \n",
            "1                3.0         moderate_poly  ...              4.0   \n",
            "2                4.0         moderate_poly  ...              NaN   \n",
            "3                2.0          dual_therapy  ...              7.0   \n",
            "4                2.0          dual_therapy  ...              9.0   \n",
            "\n",
            "                                       all_reactions num_reactions  \\\n",
            "0  [BLOOD CREATINE INCREASED, FALL, SINUSITIS, SK...          76.0   \n",
            "1  [PNEUMONITIS, ABDOMINAL PAIN UPPER, CARCINOID ...          24.0   \n",
            "2  [STAPHYLOCOCCAL INFECTION, MYCOBACTERIUM HAEMO...           4.0   \n",
            "3             [DRUG HYPERSENSITIVITY, DRUG ERUPTION]           2.0   \n",
            "4  [PHOTOSENSITIVITY REACTION, PARKINSON'S DISEAS...          32.0   \n",
            "\n",
            "   has_serious_reaction reaction_severity outcome_codes is_serious_outcome  \\\n",
            "0                  True           extreme          [OT]              False   \n",
            "1                  True           extreme      [OT, HO]               True   \n",
            "2                 False          moderate          [OT]              False   \n",
            "3                 False               few           NaN                NaN   \n",
            "4                 False           extreme          [HO]               True   \n",
            "\n",
            "                                outcome_descriptions  \\\n",
            "0          [Other Serious (Important Medical Event)]   \n",
            "1  [Other Serious (Important Medical Event), Hosp...   \n",
            "2          [Other Serious (Important Medical Event)]   \n",
            "3                                                NaN   \n",
            "4           [Hospitalization - Initial or Prolonged]   \n",
            "\n",
            "                                         indications num_indications  \n",
            "0                            [NEUROENDOCRINE TUMOUR]             1.0  \n",
            "1  [PANCREATIC NEUROENDOCRINE TUMOUR, CARCINOID T...             2.0  \n",
            "2  [RENAL TRANSPLANT, IMMUNOSUPPRESSANT DRUG THER...             2.0  \n",
            "3                                                NaN             NaN  \n",
            "4                   [ANTIBIOTIC PROPHYLAXIS, ASTHMA]             2.0  \n",
            "\n",
            "[5 rows x 21 columns]\n",
            "\n",
            "============================================================\n",
            "COLUMNS IN FINAL DATASET\n",
            "============================================================\n",
            "['primaryid', 'age_years', 'age_group', 'sex_clean', 'occr_country', 'is_elderly', 'is_pediatric', 'suspect_drugs', 'num_suspect_drugs', 'polypharmacy_category', 'concomitant_drugs', 'num_concom_drugs', 'all_reactions', 'num_reactions', 'has_serious_reaction', 'reaction_severity', 'outcome_codes', 'is_serious_outcome', 'outcome_descriptions', 'indications', 'num_indications']\n",
            "\n",
            "============================================================\n",
            "QUICK STATISTICS\n",
            "============================================================\n",
            "Unique patients: 2,848,079\n",
            "Elderly patients: 670,552\n",
            "Pediatric patients: 135,067\n",
            "Cases with serious reactions: 226,449\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create directory structure if it doesn't exist\n",
        "save_directory = '/content/drive/MyDrive/Dataset/final_dataset/'\n",
        "os.makedirs(save_directory, exist_ok=True)\n",
        "\n",
        "# Define the save path\n",
        "pkl_file_path = f'{save_directory}final_merged_all_7quarters.pkl'\n",
        "\n",
        "# Save the final_dataset to pickle format\n",
        "print(\"=\"*60)\n",
        "print(\"SAVING FINAL DATASET TO GOOGLE DRIVE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "try:\n",
        "    # Save to pickle\n",
        "    final_dataset.to_pickle(pkl_file_path)\n",
        "\n",
        "    # Verify it saved correctly\n",
        "    file_size_mb = os.path.getsize(pkl_file_path) / (1024**2)\n",
        "\n",
        "    print(f\"Successfully saved!\")\n",
        "    print(f\"\\nFile Details:\")\n",
        "    print(f\"   Path: {pkl_file_path}\")\n",
        "    print(f\"   Size: {file_size_mb:.2f} MB\")\n",
        "    print(f\"   Cases: {final_dataset.shape[0]:,}\")\n",
        "    print(f\"   Features: {final_dataset.shape[1]}\")\n",
        "\n",
        "    # Quick verification - try loading it back\n",
        "    print(f\"\\nVerifying saved file...\")\n",
        "    test_load = pd.read_pickle(pkl_file_path)\n",
        "    print(f\"   File can be loaded successfully\")\n",
        "    print(f\"   Verified shape: {test_load.shape}\")\n",
        "\n",
        "    print(f\"\\n✨ Your data is safely stored in Google Drive!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error saving file: {str(e)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkTyy2djhLGD",
        "outputId": "549a1748-e9e5-4767-ec72-31e62d0be365"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "SAVING FINAL DATASET TO GOOGLE DRIVE\n",
            "============================================================\n",
            "Successfully saved!\n",
            "\n",
            "File Details:\n",
            "   Path: /content/drive/MyDrive/Dataset/final_dataset/final_merged_all_7quarters.pkl\n",
            "   Size: 719.92 MB\n",
            "   Cases: 2,848,079\n",
            "   Features: 21\n",
            "\n",
            "Verifying saved file...\n",
            "   File can be loaded successfully\n",
            "   Verified shape: (2848079, 21)\n",
            "\n",
            "✨ Your data is safely stored in Google Drive!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0IoVckyziZlZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}